{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 09:34:09.611470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from copy import deepcopy\n",
    "from sklearn.utils import class_weight\n",
    "import joblib\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    smart_attack_path = 'attack_10_10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bin(hex_num):\n",
    "    \n",
    "    binary_value = bin(int(str(hex_num), 16))[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def int_to_bin(int_num):\n",
    "    \n",
    "    binary_value = bin(int_num)[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def pad(value, length):\n",
    "    \n",
    "    curr_length = len(str(value))\n",
    "    \n",
    "    zeros = '0' * (length - curr_length)\n",
    "    \n",
    "    return zeros + value\n",
    "\n",
    "hex_to_dec = lambda x: int(x, 16)\n",
    "\n",
    "def transform_data(data):\n",
    "\n",
    "    data['ID'] = data['ID'].apply(hex_to_dec)\n",
    "    data['Payload'] = data['Payload'].apply(hex_to_dec)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_columns(df):\n",
    "    \n",
    "    for dlc in [2,5,6]:\n",
    "\n",
    "        df.loc[df['dlc'] == dlc, df.columns[3:]] = df.loc[df['dlc'] == dlc, df.columns[3:]].shift(periods=8-dlc, axis='columns', fill_value='00')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_attack_data(data_path):\n",
    "    \n",
    "    columns = ['timestamp','can_id', 'dlc', 'data0', 'data1', 'data2', 'data3', 'data4', \n",
    "           'data5', 'data6', 'data7', 'flag']\n",
    "    \n",
    "    data = pd.read_csv(data_path, names = columns)\n",
    "\n",
    "    data = shift_columns(data)\n",
    "    \n",
    "    ##Replacing all NaNs with '00' \n",
    "    data = data.replace(np.NaN, '00')\n",
    "    \n",
    "    ##Joining all data columns to put all data in one column\n",
    "    data_cols = ['data0', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
    "    \n",
    "    ##The data column is in hexadecimal\n",
    "    data['data'] = data[data_cols].apply(''.join, axis=1)\n",
    "    data.drop(columns = data_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    ##Converting columns to decimal\n",
    "    data['can_id'] = data['can_id'].apply(hex_to_dec)\n",
    "    data['data'] = data['data'].apply(hex_to_dec)\n",
    "\n",
    "    data = data.assign(IAT=data['timestamp'].diff().fillna(0))\n",
    "    \n",
    "    return data[:150_000]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack = pd.read_csv(smart_attack_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify_data(X, y, seq_size=10):\n",
    "    max_index = len(X) - seq_size + 1\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "\n",
    "    for i in range(0, max_index, seq_size):\n",
    "        X_seq.append(X[i:i+seq_size])  # Append the sequence from DataFrame 'X'\n",
    "        try:\n",
    "            y_seq.append(1 if 1 in y[i:i+seq_size].values else 0)  # Check for '1' in 'y' values\n",
    "        except:\n",
    "             y_seq.append(1 if 1 in y[i:i+seq_size] else 0)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack.drop(columns = ['Timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smart = smart_attack.drop(['label'], axis = 1).values\n",
    "y_smart = smart_attack['label']\n",
    "y_tri = y_smart.copy(deep = True)\n",
    "y_smart = y_smart.replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([100000,  47462]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_smart, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_smart, y_seq_smart = sequencify_data(X_smart, y_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 1350, 13396]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_seq_smart, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X_seq, y_seq):\n",
    "    # Get indices for label 0 and label 1\n",
    "    zero_indices = np.where(y_seq == 0)[0]\n",
    "    one_indices = np.where(y_seq == 1)[0]\n",
    "\n",
    "    # Find the number of samples for label 0\n",
    "    num_zeros = len(zero_indices)\n",
    "\n",
    "    # Randomly sample an equal number of samples from label 1\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "    sampled_one_indices = np.random.choice(one_indices, num_zeros, replace=False)\n",
    "\n",
    "    # Combine the indices of label 0 and sampled label 1\n",
    "    balanced_indices = np.concatenate([zero_indices, sampled_one_indices])\n",
    "\n",
    "    # Shuffle the balanced indices to avoid any ordering issues\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Subset X_seq and y_seq based on the balanced indices\n",
    "    X_seq_balanced = X_seq[balanced_indices]\n",
    "    y_seq_balanced = y_seq[balanced_indices]\n",
    "\n",
    "    return X_seq_balanced, y_seq_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_smart, y_seq_smart = balance_data(X_seq_smart, y_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1350, 1350]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_seq_smart, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smart, X_test_smart, y_train_smart, y_test_smart = train_test_split(X_smart, y_smart, test_size=0.3, random_state = 42)\n",
    "X_train_seq_smart, X_test_seq_smart, y_train_seq_smart, y_test_seq_smart = train_test_split(X_seq_smart, y_seq_smart, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1890, 10, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq_smart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('scaler_m0.sav')\n",
    "\n",
    "X_train_smart = scaler.fit_transform(X_train_smart)\n",
    "X_test_smart = scaler.transform(X_test_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.mean(X_train_seq_smart, axis=(0, 1))  # Mean of each feature across training samples and timesteps\n",
    "train_stds = np.std(X_train_seq_smart, axis=(0, 1))    # Standard deviation of each feature across training samples and timesteps\n",
    "\n",
    "# Handle case where std is zero (to avoid division by zero)\n",
    "train_stds[train_stds == 0] = 1e-8\n",
    "\n",
    "# Standardize the training set\n",
    "X_train_seq_smart = (X_train_seq_smart - train_means) / train_stds\n",
    "\n",
    "# Standardize the test set using the training set's mean and std\n",
    "X_test_seq_smart = (X_test_seq_smart - train_means) / train_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1890, 10, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810, 10, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103223, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  classes = np.unique(y_train_smart),\n",
    "#                                                  y = y_train_smart)\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "# seq_class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  classes = np.unique(y_train_seq_smart),\n",
    "#                                                  y = y_train_seq_smart)\n",
    "# seq_class_weights = dict(enumerate(seq_class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train_smart, y_train_smart) \n",
    "# X_train_smote, y_train_smote = X_train, y_train_smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([70127, 70127]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_smote, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 09:34:11.887017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 09:34:11.892716: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.9722 - accuracy: 0.6809 - val_loss: 1.1012 - val_accuracy: 0.3989\n",
      "Epoch 2/100\n",
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.5948 - accuracy: 0.6960 - val_loss: 0.7398 - val_accuracy: 0.4821\n",
      "Epoch 3/100\n",
      "3507/3507 [==============================] - 10s 3ms/step - loss: 0.5823 - accuracy: 0.7006 - val_loss: 0.8207 - val_accuracy: 0.4285\n",
      "Epoch 4/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.5687 - accuracy: 0.7096 - val_loss: 0.6663 - val_accuracy: 0.5654\n",
      "Epoch 5/100\n",
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.5593 - accuracy: 0.7160 - val_loss: 0.9183 - val_accuracy: 0.4103\n",
      "Epoch 6/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.5482 - accuracy: 0.7265 - val_loss: 0.9654 - val_accuracy: 0.4127\n",
      "Epoch 7/100\n",
      "3507/3507 [==============================] - 7s 2ms/step - loss: 0.5357 - accuracy: 0.7390 - val_loss: 0.7611 - val_accuracy: 0.4658\n",
      "Epoch 8/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.5239 - accuracy: 0.7462 - val_loss: 0.6226 - val_accuracy: 0.6484\n",
      "Epoch 9/100\n",
      "3507/3507 [==============================] - 10s 3ms/step - loss: 0.5097 - accuracy: 0.7541 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
      "Epoch 10/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.4975 - accuracy: 0.7645 - val_loss: 0.6983 - val_accuracy: 0.6404\n",
      "Epoch 11/100\n",
      "3507/3507 [==============================] - 10s 3ms/step - loss: 0.4859 - accuracy: 0.7723 - val_loss: 0.5692 - val_accuracy: 0.7148\n",
      "Epoch 12/100\n",
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.4770 - accuracy: 0.7779 - val_loss: 0.7319 - val_accuracy: 0.6073\n",
      "Epoch 13/100\n",
      "3507/3507 [==============================] - 8s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.7073 - val_accuracy: 0.6269\n",
      "Epoch 14/100\n",
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.4615 - accuracy: 0.7845 - val_loss: 0.5610 - val_accuracy: 0.7443\n",
      "Epoch 15/100\n",
      "3507/3507 [==============================] - 10s 3ms/step - loss: 0.4551 - accuracy: 0.7880 - val_loss: 0.7565 - val_accuracy: 0.5890\n",
      "Epoch 16/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.4489 - accuracy: 0.7895 - val_loss: 0.5890 - val_accuracy: 0.7052\n",
      "Epoch 17/100\n",
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.4449 - accuracy: 0.7918 - val_loss: 0.5914 - val_accuracy: 0.6862\n",
      "Epoch 18/100\n",
      "3507/3507 [==============================] - 10s 3ms/step - loss: 0.4415 - accuracy: 0.7924 - val_loss: 0.6701 - val_accuracy: 0.6231\n",
      "Epoch 19/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.4359 - accuracy: 0.7958 - val_loss: 0.5810 - val_accuracy: 0.6911\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "\n",
    "print(\"-----MLP-------\")\n",
    "\n",
    "mlp = load_model('mlp_m0.h5')\n",
    "\n",
    "mlp.compile(optimizer='adam',\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "mlp_hist = mlp.fit(X_train_smote, y_train_smote, epochs=100, callbacks = [es], validation_split=0.2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      " 666/1383 [=============>................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383/1383 [==============================] - 2s 1ms/step\n",
      "--------Smart--------\n",
      "ACCURACY:  0.7734804132100636\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.79      0.82     29873\n",
      "         1.0       0.63      0.75      0.68     14366\n",
      "\n",
      "    accuracy                           0.77     44239\n",
      "   macro avg       0.75      0.77      0.75     44239\n",
      "weighted avg       0.79      0.77      0.78     44239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "print(\"-----MLP-------\")\n",
    "threshold = 0.5\n",
    "mlp_preds = mlp.predict(X_test_smart, batch_size = 32)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Smart--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_smart, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_smart, mlp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "Epoch 1/1000\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 1.8008 - accuracy: 0.5754 - val_loss: 0.6853 - val_accuracy: 0.6587\n",
      "Epoch 2/1000\n",
      "48/48 [==============================] - 7s 155ms/step - loss: 0.6655 - accuracy: 0.6607 - val_loss: 0.6100 - val_accuracy: 0.7487\n",
      "Epoch 3/1000\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.5851 - accuracy: 0.7196 - val_loss: 0.5470 - val_accuracy: 0.7751\n",
      "Epoch 4/1000\n",
      "48/48 [==============================] - 1s 25ms/step - loss: 0.5059 - accuracy: 0.7626 - val_loss: 0.4720 - val_accuracy: 0.7989\n",
      "Epoch 5/1000\n",
      "48/48 [==============================] - 2s 34ms/step - loss: 0.4385 - accuracy: 0.7937 - val_loss: 0.4284 - val_accuracy: 0.7831\n",
      "Epoch 6/1000\n",
      "48/48 [==============================] - 2s 36ms/step - loss: 0.3930 - accuracy: 0.8142 - val_loss: 0.4343 - val_accuracy: 0.8175\n",
      "Epoch 7/1000\n",
      "48/48 [==============================] - 1s 23ms/step - loss: 0.3587 - accuracy: 0.8386 - val_loss: 0.3703 - val_accuracy: 0.8492\n",
      "Epoch 8/1000\n",
      "48/48 [==============================] - 1s 25ms/step - loss: 0.3268 - accuracy: 0.8571 - val_loss: 0.3971 - val_accuracy: 0.8175\n",
      "Epoch 9/1000\n",
      "48/48 [==============================] - 1s 24ms/step - loss: 0.2965 - accuracy: 0.8717 - val_loss: 0.2884 - val_accuracy: 0.8810\n",
      "Epoch 10/1000\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2670 - accuracy: 0.8843 - val_loss: 0.3672 - val_accuracy: 0.8677\n",
      "Epoch 11/1000\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.2306 - accuracy: 0.9048 - val_loss: 0.2813 - val_accuracy: 0.9048\n",
      "Epoch 12/1000\n",
      "48/48 [==============================] - 3s 62ms/step - loss: 0.2131 - accuracy: 0.9140 - val_loss: 0.4454 - val_accuracy: 0.8915\n",
      "Epoch 13/1000\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.2386 - accuracy: 0.9147 - val_loss: 0.2336 - val_accuracy: 0.9127\n",
      "Epoch 14/1000\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1778 - accuracy: 0.9332 - val_loss: 0.2076 - val_accuracy: 0.9259\n",
      "Epoch 15/1000\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1517 - accuracy: 0.9405 - val_loss: 0.2203 - val_accuracy: 0.9206\n",
      "Epoch 16/1000\n",
      "48/48 [==============================] - 2s 48ms/step - loss: 0.1609 - accuracy: 0.9339 - val_loss: 0.2226 - val_accuracy: 0.9101\n",
      "Epoch 17/1000\n",
      "48/48 [==============================] - 3s 71ms/step - loss: 0.1339 - accuracy: 0.9438 - val_loss: 0.1979 - val_accuracy: 0.9233\n",
      "Epoch 18/1000\n",
      "48/48 [==============================] - 5s 99ms/step - loss: 0.1195 - accuracy: 0.9524 - val_loss: 0.2157 - val_accuracy: 0.9365\n",
      "Epoch 19/1000\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 0.1272 - accuracy: 0.9484 - val_loss: 0.2068 - val_accuracy: 0.9365\n",
      "Epoch 20/1000\n",
      "48/48 [==============================] - 4s 73ms/step - loss: 0.1052 - accuracy: 0.9557 - val_loss: 0.2664 - val_accuracy: 0.9127\n",
      "Epoch 21/1000\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 0.1011 - accuracy: 0.9577 - val_loss: 0.2260 - val_accuracy: 0.9312\n",
      "Epoch 22/1000\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.1056 - accuracy: 0.9590 - val_loss: 0.1996 - val_accuracy: 0.9312\n"
     ]
    }
   ],
   "source": [
    "##LSTM\n",
    "\n",
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm = load_model('lstm_m0.h5')\n",
    "\n",
    "lstm.compile(\n",
    "    loss = BinaryCrossentropy(from_logits = False),\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "lstm_hist = lstm.fit(X_train_seq_smart, y_train_seq_smart, batch_size = 32, validation_split = 0.2,\n",
    "        callbacks = [es], epochs = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "--------Smart--------\n",
      "ACCURACY:  0.9160493827160494\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       392\n",
      "           1       0.93      0.90      0.92       418\n",
      "\n",
      "    accuracy                           0.92       810\n",
      "   macro avg       0.92      0.92      0.92       810\n",
      "weighted avg       0.92      0.92      0.92       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm_preds = lstm.predict(X_test_seq_smart, batch_size=32)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Smart--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_seq_smart, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_seq_smart, lstm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Smart--------\n",
      "ACCURACY:  0.7350527814824024\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.87      0.82     29873\n",
      "         1.0       0.63      0.44      0.52     14366\n",
      "\n",
      "    accuracy                           0.74     44239\n",
      "   macro avg       0.70      0.66      0.67     44239\n",
      "weighted avg       0.72      0.74      0.72     44239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = joblib.load('dt_m0.pkl')\n",
    "dt.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "dt_preds = dt.predict(X_test_smart)\n",
    "\n",
    "print(\"--------Smart--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_smart, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_smart, dt_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
