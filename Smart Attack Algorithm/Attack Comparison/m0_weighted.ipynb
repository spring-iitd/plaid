{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 08:42:40.109995: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fuzzy_dataset.csv', 'normal_run_data.7z', 'normal_run_data', 'DoS_dataset.csv', 'RPM_dataset.csv', 'gear_dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'Car-Hacking/'\n",
    "print(os.listdir(data_folder))\n",
    "smart_attack_path = 'attack_10_10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_data_path = os.path.join(data_folder, 'RPM_dataset.csv')\n",
    "gear_data_path = os.path.join(data_folder, 'gear_dataset.csv')\n",
    "dos_data_path = os.path.join(data_folder, 'DoS_dataset.csv')\n",
    "# fuzzy_data_path = os.path.join(data_folder, 'Fuzzy_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bin(hex_num):\n",
    "    \n",
    "    binary_value = bin(int(str(hex_num), 16))[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def int_to_bin(int_num):\n",
    "    \n",
    "    binary_value = bin(int_num)[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def pad(value, length):\n",
    "    \n",
    "    curr_length = len(str(value))\n",
    "    \n",
    "    zeros = '0' * (length - curr_length)\n",
    "    \n",
    "    return zeros + value\n",
    "\n",
    "hex_to_dec = lambda x: int(x, 16)\n",
    "\n",
    "def transform_data(data):\n",
    "\n",
    "    data['ID'] = data['ID'].apply(hex_to_dec)\n",
    "    data['Payload'] = data['Payload'].apply(hex_to_dec)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_columns(df):\n",
    "    \n",
    "    for dlc in [2,5,6]:\n",
    "\n",
    "        df.loc[df['dlc'] == dlc, df.columns[3:]] = df.loc[df['dlc'] == dlc, df.columns[3:]].shift(periods=8-dlc, axis='columns', fill_value='00')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_attack_data(data_path):\n",
    "    \n",
    "    columns = ['timestamp','can_id', 'dlc', 'data0', 'data1', 'data2', 'data3', 'data4', \n",
    "           'data5', 'data6', 'data7', 'flag']\n",
    "    \n",
    "    data = pd.read_csv(data_path, names = columns)\n",
    "\n",
    "    data = shift_columns(data)\n",
    "    \n",
    "    ##Replacing all NaNs with '00' \n",
    "    data = data.replace(np.NaN, '00')\n",
    "    \n",
    "    ##Joining all data columns to put all data in one column\n",
    "    data_cols = ['data0', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
    "    \n",
    "    ##The data column is in hexadecimal\n",
    "    data['data'] = data[data_cols].apply(''.join, axis=1)\n",
    "    data.drop(columns = data_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    ##Converting columns to decimal\n",
    "    data['can_id'] = data['can_id'].apply(hex_to_dec)\n",
    "    data['data'] = data['data'].apply(hex_to_dec)\n",
    "\n",
    "    data = data.assign(IAT=data['timestamp'].diff().fillna(0))\n",
    "    \n",
    "    return data[:50_000]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_data = read_attack_data(rpm_data_path)\n",
    "gear_data = read_attack_data(gear_data_path)\n",
    "dos_data = read_attack_data(dos_data_path)\n",
    "smart_attack = pd.read_csv(smart_attack_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3387377/3946342637.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  gear_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3387377/3946342637.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gear_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3387377/3946342637.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dos_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3387377/3946342637.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dos_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3387377/3946342637.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  rpm_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3387377/3946342637.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rpm_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "gear_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
    "dos_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
    "rpm_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
    "\n",
    "impersonation_data = pd.concat([gear_data,rpm_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOS: flag\n",
      "0    38580\n",
      "1    11420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Gear: flag\n",
      "0    40848\n",
      "1     9152\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RPM: flag\n",
      "0    40554\n",
      "1     9446\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Impersonation Combined: flag\n",
      "0    81402\n",
      "1    18598\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"DOS:\",dos_data['flag'].value_counts())\n",
    "print()\n",
    "print(\"Gear:\",gear_data['flag'].value_counts())\n",
    "print()\n",
    "print(\"RPM:\",rpm_data['flag'].value_counts())\n",
    "print()\n",
    "print(\"Impersonation Combined:\",impersonation_data['flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify_data(X, y, seq_size=10):\n",
    "    max_index = len(X) - seq_size + 1\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "\n",
    "    for i in range(0, max_index, seq_size):\n",
    "        X_seq.append(X[i:i+seq_size])  # Append the sequence from DataFrame 'X'\n",
    "        try:\n",
    "            y_seq.append(1 if 1 in y[i:i+seq_size].values else 0)  # Check for '1' in 'y' values\n",
    "        except:\n",
    "             y_seq.append(1 if 1 in y[i:i+seq_size] else 0)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack.drop(columns = ['Timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dos = dos_data[['can_id', 'dlc', 'data', 'IAT']].values\n",
    "y_dos = dos_data['flag'].values\n",
    "\n",
    "X_imp = impersonation_data[['can_id', 'dlc', 'data', 'IAT']].values\n",
    "y_imp = impersonation_data['flag'].values\n",
    "\n",
    "\n",
    "X_smart = smart_attack.drop(['label'], axis = 1).values\n",
    "y_smart = smart_attack['label']\n",
    "y_tri = y_smart.copy(deep = True)\n",
    "y_smart = y_smart.replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_dos, y_seq_dos = sequencify_data(X_dos, y_dos)\n",
    "X_seq_imp, y_seq_imp = sequencify_data(X_imp, y_imp)\n",
    "X_seq_smart, y_seq_smart = sequencify_data(X_smart, y_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X_seq, y_seq):\n",
    "    # Get indices for label 0 and label 1\n",
    "    zero_indices = np.where(y_seq == 0)[0]\n",
    "    one_indices = np.where(y_seq == 1)[0]\n",
    "\n",
    "    # Find the number of samples for label 0\n",
    "    num_zeros = len(zero_indices)\n",
    "\n",
    "    # Randomly sample an equal number of samples from label 1\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "    sampled_one_indices = np.random.choice(one_indices, num_zeros, replace=False)\n",
    "\n",
    "    # Combine the indices of label 0 and sampled label 1\n",
    "    balanced_indices = np.concatenate([zero_indices, sampled_one_indices])\n",
    "\n",
    "    # Shuffle the balanced indices to avoid any ordering issues\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Subset X_seq and y_seq based on the balanced indices\n",
    "    X_seq_balanced = X_seq[balanced_indices]\n",
    "    y_seq_balanced = y_seq[balanced_indices]\n",
    "\n",
    "    return X_seq_balanced, y_seq_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_smart, y_seq_smart = balance_data(X_seq_smart, y_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dos, X_test_dos, y_train_dos, y_test_dos = train_test_split(X_dos, y_dos, test_size=0.3, random_state = 42)\n",
    "X_train_seq_dos, X_test_seq_dos, y_train_seq_dos, y_test_seq_dos = train_test_split(X_seq_dos, y_seq_dos, test_size = 0.3, shuffle = True)\n",
    "\n",
    "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(X_imp, y_imp, test_size=0.3, random_state = 42)\n",
    "X_train_seq_imp, X_test_seq_imp, y_train_seq_imp, y_test_seq_imp = train_test_split(X_seq_imp, y_seq_imp, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOS Train: (array([0, 1]), array([27011,  7989]))\n",
      "\n",
      "Impersonation Train: (array([0, 1]), array([56927, 13073]))\n",
      "\n",
      "\n",
      "DOS Train Sequencified: (array([0, 1]), array([2014, 1486]))\n",
      "\n",
      "Impersonation Train Sequencified: (array([0, 1]), array([2893, 4107]))\n"
     ]
    }
   ],
   "source": [
    "print(\"DOS Train:\", np.unique(y_train_dos, return_counts = True))\n",
    "print()\n",
    "print(\"Impersonation Train:\", np.unique(y_train_imp, return_counts = True))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"DOS Train Sequencified:\", np.unique(y_train_seq_dos, return_counts = True))\n",
    "print()\n",
    "print(\"Impersonation Train Sequencified:\", np.unique(y_train_seq_imp, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing dataset\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train_dos)\n",
    "scaler.fit(X_train_imp)\n",
    "\n",
    "X_train = np.concatenate((X_train_dos, X_train_imp), axis = 0)\n",
    "y_train = np.concatenate((y_train_dos, y_train_imp), axis = 0)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test_dos = scaler.transform(X_test_dos)\n",
    "X_test_imp = scaler.transform(X_test_imp)\n",
    "\n",
    "\n",
    "mean = np.mean(np.concatenate((X_train_seq_dos, X_train_seq_imp), axis = 0),axis=(0,1))\n",
    "std = np.mean(np.concatenate((X_train_seq_dos, X_train_seq_imp), axis = 0), axis=(0,1))\n",
    "\n",
    "X_train_seq = np.concatenate((X_train_seq_dos, X_train_seq_imp), axis = 0)\n",
    "y_train_seq = np.concatenate((y_train_seq_dos, y_train_seq_imp), axis = 0)\n",
    "\n",
    "X_train_seq -= mean\n",
    "X_train_seq /= std\n",
    "\n",
    "\n",
    "X_test_seq_dos -= mean\n",
    "X_test_seq_dos /= std\n",
    "\n",
    "X_test_seq_imp -= mean\n",
    "X_test_seq_imp /= std\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train, y_train) \n",
    "\n",
    "seq_class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes = np.unique(y_train_seq),\n",
    "                                                 y = y_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_seq, y_train_seq = balance_data(X_train_seq, y_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([83938, 83938]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train_smote, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0699001426533523, 1: 0.9386733416770964}\n"
     ]
    }
   ],
   "source": [
    "seq_class_weights = dict(enumerate(seq_class_weights))\n",
    "print(seq_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 08:43:57.535392: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 08:43:57.540524: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4197/4197 [==============================] - 11s 3ms/step - loss: 0.1971 - accuracy: 0.9214 - val_loss: 0.1826 - val_accuracy: 0.9937\n",
      "Epoch 2/100\n",
      "4197/4197 [==============================] - 11s 3ms/step - loss: 0.1400 - accuracy: 0.9479 - val_loss: 0.0704 - val_accuracy: 0.9943\n",
      "Epoch 3/100\n",
      "4197/4197 [==============================] - 12s 3ms/step - loss: 0.1272 - accuracy: 0.9526 - val_loss: 0.0833 - val_accuracy: 0.9947\n",
      "Epoch 4/100\n",
      "4197/4197 [==============================] - 12s 3ms/step - loss: 0.1198 - accuracy: 0.9544 - val_loss: 0.0992 - val_accuracy: 0.9846\n",
      "Epoch 5/100\n",
      "4197/4197 [==============================] - 12s 3ms/step - loss: 0.1137 - accuracy: 0.9565 - val_loss: 0.1071 - val_accuracy: 0.9844\n",
      "Epoch 6/100\n",
      "4197/4197 [==============================] - 12s 3ms/step - loss: 0.1065 - accuracy: 0.9602 - val_loss: 0.0750 - val_accuracy: 0.9960\n",
      "Epoch 7/100\n",
      "4197/4197 [==============================] - 12s 3ms/step - loss: 0.0987 - accuracy: 0.9640 - val_loss: 0.0777 - val_accuracy: 0.9977\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "\n",
    "print(\"-----MLP-------\")\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Input(shape = (4)))\n",
    "mlp.add(Dense(128, activation = 'relu'))\n",
    "mlp.add(Dense(64, activation = 'relu'))\n",
    "mlp.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "mlp.compile(optimizer='adam',\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "mlp_hist = mlp.fit(X_train_smote, y_train_smote, epochs=100, callbacks = [es], validation_split=0.2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "--------DOS--------\n",
      "ACCURACY:  0.9315333333333333\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     11569\n",
      "           1       0.77      1.00      0.87      3431\n",
      "\n",
      "    accuracy                           0.93     15000\n",
      "   macro avg       0.89      0.95      0.91     15000\n",
      "weighted avg       0.95      0.93      0.93     15000\n",
      "\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "--------Impersonation--------\n",
      "ACCURACY:  0.9453\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97     24475\n",
      "           1       0.77      1.00      0.87      5525\n",
      "\n",
      "    accuracy                           0.95     30000\n",
      "   macro avg       0.89      0.96      0.92     30000\n",
      "weighted avg       0.96      0.95      0.95     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "print(\"-----MLP-------\")\n",
    "threshold = 0.5\n",
    "mlp_preds = mlp.predict(X_test_dos, batch_size = 8196)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------DOS--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_dos, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_dos, mlp_preds))\n",
    "\n",
    "mlp_preds = mlp.predict(X_test_imp, batch_size = 8196)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Impersonation--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_imp, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_imp, mlp_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 30s 109ms/step - loss: 0.4881 - accuracy: 0.7444 - val_loss: 0.4209 - val_accuracy: 0.8152\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.3053 - accuracy: 0.8758 - val_loss: 0.3183 - val_accuracy: 0.8757\n",
      "Epoch 3/1000\n",
      "150/263 [================>.............] - ETA: 6s - loss: 0.2149 - accuracy: 0.9202"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 17s 66ms/step - loss: 0.2101 - accuracy: 0.9221 - val_loss: 0.2507 - val_accuracy: 0.9105\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 0.1701 - accuracy: 0.9387 - val_loss: 0.1732 - val_accuracy: 0.9419\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 0.1311 - accuracy: 0.9495 - val_loss: 0.1457 - val_accuracy: 0.9490\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.1116 - accuracy: 0.9581 - val_loss: 0.1540 - val_accuracy: 0.9400\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 0.1033 - accuracy: 0.9594 - val_loss: 0.1199 - val_accuracy: 0.9586\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 18s 68ms/step - loss: 0.0962 - accuracy: 0.9630 - val_loss: 0.2337 - val_accuracy: 0.9133\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 16s 60ms/step - loss: 0.0892 - accuracy: 0.9648 - val_loss: 0.1359 - val_accuracy: 0.9524\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 14s 55ms/step - loss: 0.0865 - accuracy: 0.9683 - val_loss: 0.1414 - val_accuracy: 0.9495\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 20s 75ms/step - loss: 0.0820 - accuracy: 0.9699 - val_loss: 0.0937 - val_accuracy: 0.9729\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 0.0773 - accuracy: 0.9693 - val_loss: 0.1205 - val_accuracy: 0.9600\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 9s 33ms/step - loss: 0.0686 - accuracy: 0.9736 - val_loss: 0.0909 - val_accuracy: 0.9719\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 5s 19ms/step - loss: 0.0579 - accuracy: 0.9785 - val_loss: 0.0860 - val_accuracy: 0.9714\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.1198 - val_accuracy: 0.9514\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 0.0531 - accuracy: 0.9792 - val_loss: 0.1694 - val_accuracy: 0.9371\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 11s 42ms/step - loss: 0.0549 - accuracy: 0.9789 - val_loss: 0.0941 - val_accuracy: 0.9690\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 0.0558 - accuracy: 0.9796 - val_loss: 0.0933 - val_accuracy: 0.9714\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 0.0427 - accuracy: 0.9824 - val_loss: 0.0969 - val_accuracy: 0.9681\n"
     ]
    }
   ],
   "source": [
    "##LSTM\n",
    "\n",
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(Input(shape = X_train_seq.shape[1:]))\n",
    "lstm.add(LSTM(128, activation = 'relu'))\n",
    "lstm.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "lstm.compile(\n",
    "    loss = BinaryCrossentropy(from_logits = False),\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "lstm_hist = lstm.fit(X_train_seq, y_train_seq, batch_size = 32, validation_split = 0.2,\n",
    "        callbacks = [es], epochs = 1000, class_weight = seq_class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save('lstm_m0_weighted.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "--------DOS--------\n",
      "ACCURACY:  0.978\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       867\n",
      "           1       0.96      0.99      0.97       633\n",
      "\n",
      "    accuracy                           0.98      1500\n",
      "   macro avg       0.98      0.98      0.98      1500\n",
      "weighted avg       0.98      0.98      0.98      1500\n",
      "\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "--------Impersonation--------\n",
      "ACCURACY:  0.967\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1293\n",
      "           1       0.97      0.97      0.97      1707\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.97      0.97      0.97      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm_preds = lstm.predict(X_test_seq_dos, batch_size=4096)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------DOS--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_seq_dos, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_seq_dos, lstm_preds))\n",
    "\n",
    "\n",
    "lstm_preds = lstm.predict(X_test_seq_imp, batch_size=4096)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Impersonation--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_seq_imp, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_seq_imp, lstm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DECISION TREE--------\n",
      "--------DOS--------\n",
      "ACCURACY:  0.8732666666666666\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     11569\n",
      "           1       0.64      1.00      0.78      3431\n",
      "\n",
      "    accuracy                           0.87     15000\n",
      "   macro avg       0.82      0.92      0.85     15000\n",
      "weighted avg       0.92      0.87      0.88     15000\n",
      "\n",
      "--------Impersonation--------\n",
      "ACCURACY:  0.8664333333333334\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     24475\n",
      "           1       0.58      1.00      0.73      5525\n",
      "\n",
      "    accuracy                           0.87     30000\n",
      "   macro avg       0.79      0.92      0.82     30000\n",
      "weighted avg       0.92      0.87      0.88     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 4)\n",
    "dt.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "dt_preds = dt.predict(X_test_dos)\n",
    "\n",
    "print(\"-------DECISION TREE--------\")\n",
    "\n",
    "print(\"--------DOS--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_dos, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_dos, dt_preds))\n",
    "    \n",
    "\n",
    "dt_preds = dt.predict(X_test_imp)\n",
    "\n",
    "print(\"--------Impersonation--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_imp, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_imp, dt_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack = pd.read_csv('aux_attacks_new_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_X = smart_attack.drop('label', axis = 1)\n",
    "smart_y = smart_attack['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_y_tri = smart_y.copy(deep=True)\n",
    "smart_y = smart_y.replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_X.drop(['Timestamp'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Payload</th>\n",
       "      <th>IAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.716925e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.441152e+18</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1072.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152069</th>\n",
       "      <td>608.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.202177e+18</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152070</th>\n",
       "      <td>672.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.177723e+14</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152071</th>\n",
       "      <td>809.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.779705e+18</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152072</th>\n",
       "      <td>880.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.851624e+15</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152073</th>\n",
       "      <td>1087.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.636436e+17</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152074 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  DLC       Payload       IAT\n",
       "0        848.0  8.0  3.716925e+17  0.000000\n",
       "1        704.0  8.0  1.441152e+18  0.000221\n",
       "2       1072.0  8.0  0.000000e+00  0.000554\n",
       "3       1201.0  8.0  0.000000e+00  0.000238\n",
       "4        497.0  8.0  0.000000e+00  0.000248\n",
       "...        ...  ...           ...       ...\n",
       "152069   608.0  8.0  3.202177e+18  0.000238\n",
       "152070   672.0  8.0  1.177723e+14  0.000236\n",
       "152071   809.0  8.0  9.779705e+18  0.000230\n",
       "152072   880.0  8.0  9.851624e+15  0.000247\n",
       "152073  1087.0  8.0  1.636436e+17  0.000237\n",
       "\n",
       "[152074 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smart_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify_data(X, y, seq_size=10):\n",
    "    max_index = len(X) - seq_size + 1\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "\n",
    "    for i in range(0, max_index, seq_size):\n",
    "        X_seq.append(X[i:i+seq_size])  # Append the sequence from DataFrame 'X'\n",
    "        y_seq.append(1 if 1 in y[i:i+seq_size].values else 0)  # Check for '1' in 'y' values\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "smart_X_seq, smart_y_seq_dos = sequencify_data(smart_X, smart_y)\n",
    "\n",
    "smart_X_seq -= mean\n",
    "smart_X_seq /= std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwesh/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smart_X = scaler.transform(smart_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4753/4753 [==============================] - 4s 915us/step\n",
      "SMART ATTACK EVAL\n",
      "ACCURACY:  0.6443902310717151\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.91      0.77    100000\n",
      "         1.0       0.44      0.14      0.21     52074\n",
      "\n",
      "    accuracy                           0.64    152074\n",
      "   macro avg       0.55      0.52      0.49    152074\n",
      "weighted avg       0.59      0.64      0.58    152074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_preds = mlp.predict(smart_X)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"SMART ATTACK EVAL\")\n",
    "\n",
    "print(\"ACCURACY: \", accuracy_score(smart_y, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(smart_y, mlp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "SMART ATTACK EVAL\n",
      "4/4 [==============================] - 0s 41ms/step\n",
      "ACCURACY:  0.45354113237324917\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.83      0.21      1320\n",
      "           1       0.96      0.42      0.58     13887\n",
      "\n",
      "    accuracy                           0.45     15207\n",
      "   macro avg       0.54      0.63      0.40     15207\n",
      "weighted avg       0.89      0.45      0.55     15207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----LSTM-------\")\n",
    "print(\"SMART ATTACK EVAL\")\n",
    "lstm_preds = lstm.predict(smart_X_seq, batch_size=4096)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"ACCURACY: \", accuracy_score(smart_y_seq_dos, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(smart_y_seq_dos, lstm_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DECISION TREE--------\n",
      "SMART ATTACK EVAL\n",
      "ACCURACY:  0.5969791022791535\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.81      0.73    100000\n",
      "         1.0       0.34      0.19      0.24     52074\n",
      "\n",
      "    accuracy                           0.60    152074\n",
      "   macro avg       0.50      0.50      0.48    152074\n",
      "weighted avg       0.55      0.60      0.56    152074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_preds = dt.predict(smart_X)\n",
    "\n",
    "print(\"-------DECISION TREE--------\")\n",
    "\n",
    "print(\"SMART ATTACK EVAL\")\n",
    "print(\"ACCURACY: \", accuracy_score(smart_y, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(smart_y, dt_preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
