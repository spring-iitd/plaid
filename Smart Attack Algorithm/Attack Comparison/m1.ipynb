{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 08:53:08.613938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from copy import deepcopy\n",
    "from sklearn.utils import class_weight\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack_path = 'attack_10_10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bin(hex_num):\n",
    "    \n",
    "    binary_value = bin(int(str(hex_num), 16))[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def int_to_bin(int_num):\n",
    "    \n",
    "    binary_value = bin(int_num)[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def pad(value, length):\n",
    "    \n",
    "    curr_length = len(str(value))\n",
    "    \n",
    "    zeros = '0' * (length - curr_length)\n",
    "    \n",
    "    return zeros + value\n",
    "\n",
    "hex_to_dec = lambda x: int(x, 16)\n",
    "\n",
    "def transform_data(data):\n",
    "\n",
    "    data['ID'] = data['ID'].apply(hex_to_dec)\n",
    "    data['Payload'] = data['Payload'].apply(hex_to_dec)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_columns(df):\n",
    "    \n",
    "    for dlc in [2,5,6]:\n",
    "\n",
    "        df.loc[df['dlc'] == dlc, df.columns[3:]] = df.loc[df['dlc'] == dlc, df.columns[3:]].shift(periods=8-dlc, axis='columns', fill_value='00')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_attack_data(data_path):\n",
    "    \n",
    "    columns = ['timestamp','can_id', 'dlc', 'data0', 'data1', 'data2', 'data3', 'data4', \n",
    "           'data5', 'data6', 'data7', 'flag']\n",
    "    \n",
    "    data = pd.read_csv(data_path, names = columns)\n",
    "\n",
    "    data = shift_columns(data)\n",
    "    \n",
    "    ##Replacing all NaNs with '00' \n",
    "    data = data.replace(np.NaN, '00')\n",
    "    \n",
    "    ##Joining all data columns to put all data in one column\n",
    "    data_cols = ['data0', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
    "    \n",
    "    ##The data column is in hexadecimal\n",
    "    data['data'] = data[data_cols].apply(''.join, axis=1)\n",
    "    data.drop(columns = data_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    ##Converting columns to decimal\n",
    "    data['can_id'] = data['can_id'].apply(hex_to_dec)\n",
    "    data['data'] = data['data'].apply(hex_to_dec)\n",
    "\n",
    "    data = data.assign(IAT=data['timestamp'].diff().fillna(0))\n",
    "    \n",
    "    return data[:150_000]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack = pd.read_csv(smart_attack_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify_data(X, y, seq_size=10):\n",
    "    max_index = len(X) - seq_size + 1\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "\n",
    "    for i in range(0, max_index, seq_size):\n",
    "        X_seq.append(X[i:i+seq_size])  # Append the sequence from DataFrame 'X'\n",
    "        try:\n",
    "            y_seq.append(1 if 1 in y[i:i+seq_size].values else 0)  # Check for '1' in 'y' values\n",
    "        except:\n",
    "             y_seq.append(1 if 1 in y[i:i+seq_size] else 0)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack.drop(columns = ['Timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smart = smart_attack.drop(['label'], axis = 1).values\n",
    "y_smart = smart_attack['label']\n",
    "y_tri = y_smart.copy(deep = True)\n",
    "y_smart = y_smart.replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([100000,  47462]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_smart, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_smart, y_seq_smart = sequencify_data(X_smart, y_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 1350, 13396]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_seq_smart, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X_seq, y_seq):\n",
    "    # Get indices for label 0 and label 1\n",
    "    zero_indices = np.where(y_seq == 0)[0]\n",
    "    one_indices = np.where(y_seq == 1)[0]\n",
    "\n",
    "    # Find the number of samples for label 0\n",
    "    num_zeros = len(zero_indices)\n",
    "\n",
    "    # Randomly sample an equal number of samples from label 1\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "    sampled_one_indices = np.random.choice(one_indices, num_zeros, replace=False)\n",
    "\n",
    "    # Combine the indices of label 0 and sampled label 1\n",
    "    balanced_indices = np.concatenate([zero_indices, sampled_one_indices])\n",
    "\n",
    "    # Shuffle the balanced indices to avoid any ordering issues\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Subset X_seq and y_seq based on the balanced indices\n",
    "    X_seq_balanced = X_seq[balanced_indices]\n",
    "    y_seq_balanced = y_seq[balanced_indices]\n",
    "\n",
    "    return X_seq_balanced, y_seq_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_smart, y_seq_smart = balance_data(X_seq_smart, y_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1350, 1350]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_seq_smart, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smart, X_test_smart, y_train_smart, y_test_smart = train_test_split(X_smart, y_smart, test_size=0.3, random_state = 42)\n",
    "X_train_seq_smart, X_test_seq_smart, y_train_seq_smart, y_test_seq_smart = train_test_split(X_seq_smart, y_seq_smart, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1890, 10, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq_smart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_smart = scaler.fit_transform(X_train_smart)\n",
    "X_test_smart = scaler.transform(X_test_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.mean(X_train_seq_smart, axis=(0, 1))  # Mean of each feature across training samples and timesteps\n",
    "train_stds = np.std(X_train_seq_smart, axis=(0, 1))    # Standard deviation of each feature across training samples and timesteps\n",
    "\n",
    "# Handle case where std is zero (to avoid division by zero)\n",
    "train_stds[train_stds == 0] = 1e-8\n",
    "\n",
    "# Standardize the training set\n",
    "X_train_seq_smart = (X_train_seq_smart - train_means) / train_stds\n",
    "\n",
    "# Standardize the test set using the training set's mean and std\n",
    "X_test_seq_smart = (X_test_seq_smart - train_means) / train_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1890, 10, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810, 10, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103223, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  classes = np.unique(y_train_smart),\n",
    "#                                                  y = y_train_smart)\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "# seq_class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  classes = np.unique(y_train_seq_smart),\n",
    "#                                                  y = y_train_seq_smart)\n",
    "# seq_class_weights = dict(enumerate(seq_class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train_smart, y_train_smart) \n",
    "# X_train_smote, y_train_smote = X_train, y_train_smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([70127, 70127]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_smote, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 08:53:10.682624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 08:53:10.687014: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.5811 - accuracy: 0.7025 - val_loss: 0.9150 - val_accuracy: 0.3944\n",
      "Epoch 2/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.5535 - accuracy: 0.7213 - val_loss: 0.7128 - val_accuracy: 0.5091\n",
      "Epoch 3/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.5303 - accuracy: 0.7377 - val_loss: 0.6910 - val_accuracy: 0.5401\n",
      "Epoch 4/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.5045 - accuracy: 0.7583 - val_loss: 0.6519 - val_accuracy: 0.5796\n",
      "Epoch 5/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.4818 - accuracy: 0.7707 - val_loss: 0.7187 - val_accuracy: 0.5353\n",
      "Epoch 6/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.4643 - accuracy: 0.7811 - val_loss: 0.6696 - val_accuracy: 0.6144\n",
      "Epoch 7/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.4494 - accuracy: 0.7885 - val_loss: 0.4957 - val_accuracy: 0.7366\n",
      "Epoch 8/100\n",
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.4399 - accuracy: 0.7931 - val_loss: 0.6534 - val_accuracy: 0.6382\n",
      "Epoch 9/100\n",
      "3507/3507 [==============================] - 9s 3ms/step - loss: 0.4329 - accuracy: 0.7971 - val_loss: 0.6192 - val_accuracy: 0.6538\n",
      "Epoch 10/100\n",
      "3507/3507 [==============================] - 9s 2ms/step - loss: 0.4280 - accuracy: 0.7990 - val_loss: 0.6277 - val_accuracy: 0.6860\n",
      "Epoch 11/100\n",
      "3507/3507 [==============================] - 10s 3ms/step - loss: 0.4245 - accuracy: 0.8023 - val_loss: 0.5379 - val_accuracy: 0.7336\n",
      "Epoch 12/100\n",
      "3507/3507 [==============================] - 10s 3ms/step - loss: 0.4203 - accuracy: 0.8035 - val_loss: 0.5332 - val_accuracy: 0.7175\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "\n",
    "print(\"-----MLP-------\")\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Input(shape = (4)))\n",
    "mlp.add(Dense(128, activation = 'relu'))\n",
    "mlp.add(Dense(64, activation = 'relu'))\n",
    "mlp.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "mlp.compile(optimizer='adam',\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "mlp_hist = mlp.fit(X_train_smote, y_train_smote, epochs=100, callbacks = [es], validation_split=0.2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "1383/1383 [==============================] - 2s 1ms/step\n",
      "--------Smart--------\n",
      "ACCURACY:  0.7811433350663441\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.80      0.83     29873\n",
      "         1.0       0.64      0.74      0.69     14366\n",
      "\n",
      "    accuracy                           0.78     44239\n",
      "   macro avg       0.75      0.77      0.76     44239\n",
      "weighted avg       0.79      0.78      0.78     44239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "print(\"-----MLP-------\")\n",
    "threshold = 0.5\n",
    "mlp_preds = mlp.predict(X_test_smart, batch_size = 32)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Smart--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_smart, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_smart, mlp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 4s 57ms/step - loss: 0.6520 - accuracy: 0.5999 - val_loss: 0.6140 - val_accuracy: 0.6270\n",
      "Epoch 2/1000\n",
      "48/48 [==============================] - 1s 20ms/step - loss: 0.5605 - accuracy: 0.6693 - val_loss: 0.5283 - val_accuracy: 0.7222\n",
      "Epoch 3/1000\n",
      "48/48 [==============================] - 1s 21ms/step - loss: 0.5077 - accuracy: 0.7513 - val_loss: 0.4768 - val_accuracy: 0.8016\n",
      "Epoch 4/1000\n",
      "48/48 [==============================] - 1s 19ms/step - loss: 0.4304 - accuracy: 0.7983 - val_loss: 0.4035 - val_accuracy: 0.8201\n",
      "Epoch 5/1000\n",
      "48/48 [==============================] - 1s 25ms/step - loss: 0.3759 - accuracy: 0.8340 - val_loss: 0.4045 - val_accuracy: 0.8069\n",
      "Epoch 6/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.3429 - accuracy: 0.8472 - val_loss: 0.3707 - val_accuracy: 0.8413\n",
      "Epoch 7/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.3201 - accuracy: 0.8671 - val_loss: 0.3672 - val_accuracy: 0.8333\n",
      "Epoch 8/1000\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.3043 - accuracy: 0.8730 - val_loss: 0.3644 - val_accuracy: 0.8413\n",
      "Epoch 9/1000\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.2902 - accuracy: 0.8763 - val_loss: 0.2820 - val_accuracy: 0.8836\n",
      "Epoch 10/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.2532 - accuracy: 0.9001 - val_loss: 0.2921 - val_accuracy: 0.8810\n",
      "Epoch 11/1000\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.2733 - accuracy: 0.8856 - val_loss: 0.3276 - val_accuracy: 0.8571\n",
      "Epoch 12/1000\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2213 - accuracy: 0.9120 - val_loss: 0.2367 - val_accuracy: 0.9101\n",
      "Epoch 13/1000\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.2230 - accuracy: 0.9034 - val_loss: 0.2350 - val_accuracy: 0.9101\n",
      "Epoch 14/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.2096 - accuracy: 0.9193 - val_loss: 0.2298 - val_accuracy: 0.9021\n",
      "Epoch 15/1000\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1853 - accuracy: 0.9253 - val_loss: 0.2196 - val_accuracy: 0.9074\n",
      "Epoch 16/1000\n",
      "48/48 [==============================] - 1s 25ms/step - loss: 0.1661 - accuracy: 0.9365 - val_loss: 0.2508 - val_accuracy: 0.9021\n",
      "Epoch 17/1000\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.1613 - accuracy: 0.9378 - val_loss: 0.2435 - val_accuracy: 0.9101\n",
      "Epoch 18/1000\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.3456 - accuracy: 0.8869 - val_loss: 0.3757 - val_accuracy: 0.8942\n",
      "Epoch 19/1000\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 0.2736 - accuracy: 0.9127 - val_loss: 0.2323 - val_accuracy: 0.9153\n",
      "Epoch 20/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.1796 - accuracy: 0.9332 - val_loss: 0.2383 - val_accuracy: 0.9101\n"
     ]
    }
   ],
   "source": [
    "##LSTM\n",
    "\n",
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(Input(shape = X_train_seq_smart.shape[1:]))\n",
    "lstm.add(LSTM(128, activation = 'relu'))\n",
    "lstm.add(Dense(64, activation = 'relu'))\n",
    "lstm.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "lstm.compile(\n",
    "    loss = BinaryCrossentropy(from_logits = False),\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "lstm_hist = lstm.fit(X_train_seq_smart, y_train_seq_smart, batch_size = 32, validation_split = 0.2,\n",
    "        callbacks = [es], epochs = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step\n",
      "--------Smart--------\n",
      "ACCURACY:  0.9061728395061729\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91       392\n",
      "           1       0.94      0.87      0.91       418\n",
      "\n",
      "    accuracy                           0.91       810\n",
      "   macro avg       0.91      0.91      0.91       810\n",
      "weighted avg       0.91      0.91      0.91       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm_preds = lstm.predict(X_test_seq_smart, batch_size=32)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Smart--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_seq_smart, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_seq_smart, lstm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Smart--------\n",
      "ACCURACY:  0.7350527814824024\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.87      0.82     29873\n",
      "         1.0       0.63      0.44      0.52     14366\n",
      "\n",
      "    accuracy                           0.74     44239\n",
      "   macro avg       0.70      0.66      0.67     44239\n",
      "weighted avg       0.72      0.74      0.72     44239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 4)\n",
    "dt.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "dt_preds = dt.predict(X_test_smart)\n",
    "\n",
    "print(\"--------Smart--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_smart, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_smart, dt_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
