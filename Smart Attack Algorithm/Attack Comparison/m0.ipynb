{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 08:35:01.673023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fuzzy_dataset.csv', 'normal_run_data.7z', 'normal_run_data', 'DoS_dataset.csv', 'RPM_dataset.csv', 'gear_dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'Car-Hacking/'\n",
    "print(os.listdir(data_folder))\n",
    "smart_attack_path = 'attack_10_10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_data_path = os.path.join(data_folder, 'RPM_dataset.csv')\n",
    "gear_data_path = os.path.join(data_folder, 'gear_dataset.csv')\n",
    "dos_data_path = os.path.join(data_folder, 'DoS_dataset.csv')\n",
    "# fuzzy_data_path = os.path.join(data_folder, 'Fuzzy_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bin(hex_num):\n",
    "    \n",
    "    binary_value = bin(int(str(hex_num), 16))[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def int_to_bin(int_num):\n",
    "    \n",
    "    binary_value = bin(int_num)[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def pad(value, length):\n",
    "    \n",
    "    curr_length = len(str(value))\n",
    "    \n",
    "    zeros = '0' * (length - curr_length)\n",
    "    \n",
    "    return zeros + value\n",
    "\n",
    "hex_to_dec = lambda x: int(x, 16)\n",
    "\n",
    "def transform_data(data):\n",
    "\n",
    "    data['ID'] = data['ID'].apply(hex_to_dec)\n",
    "    data['Payload'] = data['Payload'].apply(hex_to_dec)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_columns(df):\n",
    "    \n",
    "    for dlc in [2,5,6]:\n",
    "\n",
    "        df.loc[df['dlc'] == dlc, df.columns[3:]] = df.loc[df['dlc'] == dlc, df.columns[3:]].shift(periods=8-dlc, axis='columns', fill_value='00')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_attack_data(data_path):\n",
    "    \n",
    "    columns = ['timestamp','can_id', 'dlc', 'data0', 'data1', 'data2', 'data3', 'data4', \n",
    "           'data5', 'data6', 'data7', 'flag']\n",
    "    \n",
    "    data = pd.read_csv(data_path, names = columns)\n",
    "\n",
    "    data = shift_columns(data)\n",
    "    \n",
    "    ##Replacing all NaNs with '00' \n",
    "    data = data.replace(np.NaN, '00')\n",
    "    \n",
    "    ##Joining all data columns to put all data in one column\n",
    "    data_cols = ['data0', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
    "    \n",
    "    ##The data column is in hexadecimal\n",
    "    data['data'] = data[data_cols].apply(''.join, axis=1)\n",
    "    data.drop(columns = data_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    ##Converting columns to decimal\n",
    "    data['can_id'] = data['can_id'].apply(hex_to_dec)\n",
    "    data['data'] = data['data'].apply(hex_to_dec)\n",
    "\n",
    "    data = data.assign(IAT=data['timestamp'].diff().fillna(0))\n",
    "    \n",
    "    return data[:50_000]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_data = read_attack_data(rpm_data_path)\n",
    "gear_data = read_attack_data(gear_data_path)\n",
    "dos_data = read_attack_data(dos_data_path)\n",
    "smart_attack = pd.read_csv(smart_attack_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3382418/3946342637.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  gear_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3382418/3946342637.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gear_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3382418/3946342637.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dos_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3382418/3946342637.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dos_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3382418/3946342637.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  rpm_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
      "/tmp/ipykernel_3382418/3946342637.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rpm_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "gear_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
    "dos_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
    "rpm_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
    "\n",
    "impersonation_data = pd.concat([gear_data,rpm_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOS: flag\n",
      "0    38580\n",
      "1    11420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Gear: flag\n",
      "0    40848\n",
      "1     9152\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RPM: flag\n",
      "0    40554\n",
      "1     9446\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Impersonation Combined: flag\n",
      "0    81402\n",
      "1    18598\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"DOS:\",dos_data['flag'].value_counts())\n",
    "print()\n",
    "print(\"Gear:\",gear_data['flag'].value_counts())\n",
    "print()\n",
    "print(\"RPM:\",rpm_data['flag'].value_counts())\n",
    "print()\n",
    "print(\"Impersonation Combined:\",impersonation_data['flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify_data(X, y, seq_size=10):\n",
    "    max_index = len(X) - seq_size + 1\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "\n",
    "    for i in range(0, max_index, seq_size):\n",
    "        X_seq.append(X[i:i+seq_size])  # Append the sequence from DataFrame 'X'\n",
    "        try:\n",
    "            y_seq.append(1 if 1 in y[i:i+seq_size].values else 0)  # Check for '1' in 'y' values\n",
    "        except:\n",
    "             y_seq.append(1 if 1 in y[i:i+seq_size] else 0)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack.drop(columns = ['Timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dos = dos_data[['can_id', 'dlc', 'data', 'IAT']].values\n",
    "y_dos = dos_data['flag'].values\n",
    "\n",
    "X_imp = impersonation_data[['can_id', 'dlc', 'data', 'IAT']].values\n",
    "y_imp = impersonation_data['flag'].values\n",
    "\n",
    "\n",
    "X_smart = smart_attack.drop(['label'], axis = 1).values\n",
    "y_smart = smart_attack['label']\n",
    "y_tri = y_smart.copy(deep = True)\n",
    "y_smart = y_smart.replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_dos, y_seq_dos = sequencify_data(X_dos, y_dos)\n",
    "X_seq_imp, y_seq_imp = sequencify_data(X_imp, y_imp)\n",
    "X_seq_smart, y_seq_smart = sequencify_data(X_smart, y_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X_seq, y_seq):\n",
    "    # Get indices for label 0 and label 1\n",
    "    zero_indices = np.where(y_seq == 0)[0]\n",
    "    one_indices = np.where(y_seq == 1)[0]\n",
    "\n",
    "    # Find the number of samples for label 0\n",
    "    num_zeros = len(zero_indices)\n",
    "\n",
    "    # Randomly sample an equal number of samples from label 1\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "    sampled_one_indices = np.random.choice(one_indices, num_zeros, replace=False)\n",
    "\n",
    "    # Combine the indices of label 0 and sampled label 1\n",
    "    balanced_indices = np.concatenate([zero_indices, sampled_one_indices])\n",
    "\n",
    "    # Shuffle the balanced indices to avoid any ordering issues\n",
    "    np.random.shuffle(balanced_indices)\n",
    "\n",
    "    # Subset X_seq and y_seq based on the balanced indices\n",
    "    X_seq_balanced = X_seq[balanced_indices]\n",
    "    y_seq_balanced = y_seq[balanced_indices]\n",
    "\n",
    "    return X_seq_balanced, y_seq_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_smart, y_seq_smart = balance_data(X_seq_smart, y_seq_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dos, X_test_dos, y_train_dos, y_test_dos = train_test_split(X_dos, y_dos, test_size=0.3, random_state = 42)\n",
    "X_train_seq_dos, X_test_seq_dos, y_train_seq_dos, y_test_seq_dos = train_test_split(X_seq_dos, y_seq_dos, test_size = 0.3, shuffle = True)\n",
    "\n",
    "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(X_imp, y_imp, test_size=0.3, random_state = 42)\n",
    "X_train_seq_imp, X_test_seq_imp, y_train_seq_imp, y_test_seq_imp = train_test_split(X_seq_imp, y_seq_imp, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOS Train: (array([0, 1]), array([27011,  7989]))\n",
      "\n",
      "Impersonation Train: (array([0, 1]), array([56927, 13073]))\n",
      "\n",
      "\n",
      "DOS Train Sequencified: (array([0, 1]), array([2014, 1486]))\n",
      "\n",
      "Impersonation Train Sequencified: (array([0, 1]), array([2893, 4107]))\n"
     ]
    }
   ],
   "source": [
    "print(\"DOS Train:\", np.unique(y_train_dos, return_counts = True))\n",
    "print()\n",
    "print(\"Impersonation Train:\", np.unique(y_train_imp, return_counts = True))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"DOS Train Sequencified:\", np.unique(y_train_seq_dos, return_counts = True))\n",
    "print()\n",
    "print(\"Impersonation Train Sequencified:\", np.unique(y_train_seq_imp, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing dataset\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train_dos)\n",
    "scaler.fit(X_train_imp)\n",
    "\n",
    "X_train = np.concatenate((X_train_dos, X_train_imp), axis = 0)\n",
    "y_train = np.concatenate((y_train_dos, y_train_imp), axis = 0)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test_dos = scaler.transform(X_test_dos)\n",
    "X_test_imp = scaler.transform(X_test_imp)\n",
    "\n",
    "\n",
    "mean = np.mean(np.concatenate((X_train_seq_dos, X_train_seq_imp), axis = 0),axis=(0,1))\n",
    "std = np.mean(np.concatenate((X_train_seq_dos, X_train_seq_imp), axis = 0), axis=(0,1))\n",
    "\n",
    "X_train_seq = np.concatenate((X_train_seq_dos, X_train_seq_imp), axis = 0)\n",
    "y_train_seq = np.concatenate((y_train_seq_dos, y_train_seq_imp), axis = 0)\n",
    "\n",
    "X_train_seq -= mean\n",
    "X_train_seq /= std\n",
    "\n",
    "X_test_seq_dos -= mean\n",
    "X_test_seq_dos /= std\n",
    "\n",
    "X_test_seq_imp -= mean\n",
    "X_test_seq_imp /= std\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train, y_train) \n",
    "\n",
    "seq_class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes = np.unique(y_train_seq),\n",
    "                                                 y = y_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_m0.sav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler_m0.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq, y_train_seq = balance_data(X_train_seq, y_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([83938, 83938]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train_smote, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_class_weights = dict(enumerate(seq_class_weights))\n",
    "# print(seq_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 08:36:12.753412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 08:36:12.758271: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4197/4197 [==============================] - 10s 2ms/step - loss: 0.1939 - accuracy: 0.9223 - val_loss: 0.1483 - val_accuracy: 0.9922\n",
      "Epoch 2/100\n",
      "4197/4197 [==============================] - 10s 2ms/step - loss: 0.1349 - accuracy: 0.9515 - val_loss: 0.0935 - val_accuracy: 0.9846\n",
      "Epoch 3/100\n",
      "4197/4197 [==============================] - 9s 2ms/step - loss: 0.1230 - accuracy: 0.9536 - val_loss: 0.1308 - val_accuracy: 0.9841\n",
      "Epoch 4/100\n",
      "4197/4197 [==============================] - 8s 2ms/step - loss: 0.1163 - accuracy: 0.9557 - val_loss: 0.1190 - val_accuracy: 0.9953\n",
      "Epoch 5/100\n",
      "4197/4197 [==============================] - 7s 2ms/step - loss: 0.1088 - accuracy: 0.9586 - val_loss: 0.1176 - val_accuracy: 0.9961\n",
      "Epoch 6/100\n",
      "4197/4197 [==============================] - 10s 2ms/step - loss: 0.1032 - accuracy: 0.9620 - val_loss: 0.1021 - val_accuracy: 0.9956\n",
      "Epoch 7/100\n",
      "4197/4197 [==============================] - 9s 2ms/step - loss: 0.0928 - accuracy: 0.9666 - val_loss: 0.0989 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "\n",
    "print(\"-----MLP-------\")\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Input(shape = (4)))\n",
    "mlp.add(Dense(128, activation = 'relu'))\n",
    "mlp.add(Dense(64, activation = 'relu'))\n",
    "mlp.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "mlp.compile(optimizer='adam',\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "mlp_hist = mlp.fit(X_train_smote, y_train_smote, epochs=100, callbacks = [es], validation_split=0.2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save('mlp_m0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "2/2 [==============================] - 0s 27ms/step\n",
      "--------DOS--------\n",
      "ACCURACY:  0.9395333333333333\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96     11569\n",
      "           1       0.79      0.99      0.88      3431\n",
      "\n",
      "    accuracy                           0.94     15000\n",
      "   macro avg       0.90      0.96      0.92     15000\n",
      "weighted avg       0.95      0.94      0.94     15000\n",
      "\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "--------Impersonation--------\n",
      "ACCURACY:  0.9453333333333334\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     24475\n",
      "           1       0.78      0.98      0.87      5525\n",
      "\n",
      "    accuracy                           0.95     30000\n",
      "   macro avg       0.89      0.96      0.92     30000\n",
      "weighted avg       0.96      0.95      0.95     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "print(\"-----MLP-------\")\n",
    "threshold = 0.5\n",
    "mlp_preds = mlp.predict(X_test_dos, batch_size = 8196)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------DOS--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_dos, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_dos, mlp_preds))\n",
    "\n",
    "mlp_preds = mlp.predict(X_test_imp, batch_size = 8196)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Impersonation--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_imp, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_imp, mlp_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "Epoch 1/1000\n",
      "246/246 [==============================] - 18s 70ms/step - loss: 0.5076 - accuracy: 0.7314 - val_loss: 0.3747 - val_accuracy: 0.8324\n",
      "Epoch 2/1000\n",
      "246/246 [==============================] - 14s 55ms/step - loss: 0.3179 - accuracy: 0.8745 - val_loss: 0.2580 - val_accuracy: 0.9063\n",
      "Epoch 3/1000\n",
      "246/246 [==============================] - 23s 93ms/step - loss: 0.2321 - accuracy: 0.9108 - val_loss: 0.1773 - val_accuracy: 0.9338\n",
      "Epoch 4/1000\n",
      "246/246 [==============================] - 27s 111ms/step - loss: 0.1613 - accuracy: 0.9400 - val_loss: 0.1294 - val_accuracy: 0.9516\n",
      "Epoch 5/1000\n",
      "246/246 [==============================] - 15s 62ms/step - loss: 0.1408 - accuracy: 0.9502 - val_loss: 0.1408 - val_accuracy: 0.9460\n",
      "Epoch 6/1000\n",
      "246/246 [==============================] - 7s 27ms/step - loss: 0.1239 - accuracy: 0.9543 - val_loss: 0.1022 - val_accuracy: 0.9679\n",
      "Epoch 7/1000\n",
      "246/246 [==============================] - 9s 39ms/step - loss: 0.0979 - accuracy: 0.9654 - val_loss: 0.1316 - val_accuracy: 0.9572\n",
      "Epoch 8/1000\n",
      "246/246 [==============================] - 19s 77ms/step - loss: 0.0991 - accuracy: 0.9631 - val_loss: 0.1506 - val_accuracy: 0.9399\n",
      "Epoch 9/1000\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.1067 - accuracy: 0.9619 - val_loss: 0.0901 - val_accuracy: 0.9705\n",
      "Epoch 10/1000\n",
      "246/246 [==============================] - 11s 46ms/step - loss: 0.0826 - accuracy: 0.9696 - val_loss: 0.2517 - val_accuracy: 0.8905\n",
      "Epoch 11/1000\n",
      "246/246 [==============================] - 7s 27ms/step - loss: 0.0877 - accuracy: 0.9665 - val_loss: 0.1112 - val_accuracy: 0.9608\n",
      "Epoch 12/1000\n",
      "246/246 [==============================] - 9s 38ms/step - loss: 0.0764 - accuracy: 0.9726 - val_loss: 0.0961 - val_accuracy: 0.9659\n",
      "Epoch 13/1000\n",
      "246/246 [==============================] - 10s 42ms/step - loss: 0.0656 - accuracy: 0.9778 - val_loss: 0.0838 - val_accuracy: 0.9689\n",
      "Epoch 14/1000\n",
      "246/246 [==============================] - 11s 45ms/step - loss: 0.0700 - accuracy: 0.9759 - val_loss: 0.0850 - val_accuracy: 0.9679\n",
      "Epoch 15/1000\n",
      "246/246 [==============================] - 9s 37ms/step - loss: 0.0646 - accuracy: 0.9771 - val_loss: 0.1099 - val_accuracy: 0.9669\n",
      "Epoch 16/1000\n",
      "246/246 [==============================] - 9s 37ms/step - loss: 0.0754 - accuracy: 0.9735 - val_loss: 0.2055 - val_accuracy: 0.9180\n",
      "Epoch 17/1000\n",
      "246/246 [==============================] - 8s 34ms/step - loss: 0.0708 - accuracy: 0.9745 - val_loss: 0.0983 - val_accuracy: 0.9710\n",
      "Epoch 18/1000\n",
      "246/246 [==============================] - 8s 33ms/step - loss: 0.0621 - accuracy: 0.9776 - val_loss: 0.2869 - val_accuracy: 0.8859\n"
     ]
    }
   ],
   "source": [
    "##LSTM\n",
    "\n",
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(Input(shape = X_train_seq.shape[1:]))\n",
    "lstm.add(LSTM(128, activation = 'relu'))\n",
    "lstm.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "lstm.compile(\n",
    "    loss = BinaryCrossentropy(from_logits = False),\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "lstm_hist = lstm.fit(X_train_seq, y_train_seq, batch_size = 32, validation_split = 0.2,\n",
    "        callbacks = [es], epochs = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save('lstm_m0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "--------DOS--------\n",
      "ACCURACY:  0.9866666666666667\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       867\n",
      "           1       0.98      0.99      0.98       633\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "--------Impersonation--------\n",
      "ACCURACY:  0.971\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1293\n",
      "           1       0.98      0.96      0.97      1707\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.97      0.97      0.97      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm_preds = lstm.predict(X_test_seq_dos, batch_size=4096)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------DOS--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_seq_dos, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_seq_dos, lstm_preds))\n",
    "\n",
    "\n",
    "lstm_preds = lstm.predict(X_test_seq_imp, batch_size=4096)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"--------Impersonation--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_seq_imp, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_seq_imp, lstm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DECISION TREE--------\n",
      "--------DOS--------\n",
      "ACCURACY:  0.8732666666666666\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     11569\n",
      "           1       0.64      1.00      0.78      3431\n",
      "\n",
      "    accuracy                           0.87     15000\n",
      "   macro avg       0.82      0.92      0.85     15000\n",
      "weighted avg       0.92      0.87      0.88     15000\n",
      "\n",
      "--------Impersonation--------\n",
      "ACCURACY:  0.8664333333333334\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     24475\n",
      "           1       0.58      1.00      0.73      5525\n",
      "\n",
      "    accuracy                           0.87     30000\n",
      "   macro avg       0.79      0.92      0.82     30000\n",
      "weighted avg       0.92      0.87      0.88     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 4)\n",
    "dt.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "dt_preds = dt.predict(X_test_dos)\n",
    "\n",
    "print(\"-------DECISION TREE--------\")\n",
    "\n",
    "print(\"--------DOS--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_dos, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_dos, dt_preds))\n",
    "    \n",
    "\n",
    "dt_preds = dt.predict(X_test_imp)\n",
    "\n",
    "print(\"--------Impersonation--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_imp, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_imp, dt_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_m0.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dt, 'dt_m0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_attack = pd.read_csv('aux_attacks_new_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_X = smart_attack.drop('label', axis = 1)\n",
    "smart_y = smart_attack['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_y_tri = smart_y.copy(deep=True)\n",
    "smart_y = smart_y.replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_X.drop(['Timestamp'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Payload</th>\n",
       "      <th>IAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.716925e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.441152e+18</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1072.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152069</th>\n",
       "      <td>608.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.202177e+18</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152070</th>\n",
       "      <td>672.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.177723e+14</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152071</th>\n",
       "      <td>809.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.779705e+18</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152072</th>\n",
       "      <td>880.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.851624e+15</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152073</th>\n",
       "      <td>1087.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.636436e+17</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152074 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  DLC       Payload       IAT\n",
       "0        848.0  8.0  3.716925e+17  0.000000\n",
       "1        704.0  8.0  1.441152e+18  0.000221\n",
       "2       1072.0  8.0  0.000000e+00  0.000554\n",
       "3       1201.0  8.0  0.000000e+00  0.000238\n",
       "4        497.0  8.0  0.000000e+00  0.000248\n",
       "...        ...  ...           ...       ...\n",
       "152069   608.0  8.0  3.202177e+18  0.000238\n",
       "152070   672.0  8.0  1.177723e+14  0.000236\n",
       "152071   809.0  8.0  9.779705e+18  0.000230\n",
       "152072   880.0  8.0  9.851624e+15  0.000247\n",
       "152073  1087.0  8.0  1.636436e+17  0.000237\n",
       "\n",
       "[152074 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smart_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify_data(X, y, seq_size=10):\n",
    "    max_index = len(X) - seq_size + 1\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "\n",
    "    for i in range(0, max_index, seq_size):\n",
    "        X_seq.append(X[i:i+seq_size])  # Append the sequence from DataFrame 'X'\n",
    "        y_seq.append(1 if 1 in y[i:i+seq_size].values else 0)  # Check for '1' in 'y' values\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "smart_X_seq, smart_y_seq_dos = sequencify_data(smart_X, smart_y)\n",
    "\n",
    "smart_X_seq -= mean\n",
    "smart_X_seq /= std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwesh/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smart_X = scaler.transform(smart_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4753/4753 [==============================] - 6s 1ms/step\n",
      "SMART ATTACK EVAL\n",
      "ACCURACY:  0.6447716243407815\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.91      0.77    100000\n",
      "         1.0       0.44      0.14      0.21     52074\n",
      "\n",
      "    accuracy                           0.64    152074\n",
      "   macro avg       0.55      0.52      0.49    152074\n",
      "weighted avg       0.59      0.64      0.58    152074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_preds = mlp.predict(smart_X)\n",
    "mlp_preds = (mlp_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"SMART ATTACK EVAL\")\n",
    "\n",
    "print(\"ACCURACY: \", accuracy_score(smart_y, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(smart_y, mlp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "SMART ATTACK EVAL\n",
      "4/4 [==============================] - 0s 34ms/step\n",
      "ACCURACY:  0.3623331360557638\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.89      0.19      1320\n",
      "           1       0.97      0.31      0.47     13887\n",
      "\n",
      "    accuracy                           0.36     15207\n",
      "   macro avg       0.54      0.60      0.33     15207\n",
      "weighted avg       0.89      0.36      0.45     15207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----LSTM-------\")\n",
    "print(\"SMART ATTACK EVAL\")\n",
    "lstm_preds = lstm.predict(smart_X_seq, batch_size=4096)\n",
    "lstm_preds = (lstm_preds >= threshold).astype(int)\n",
    "\n",
    "print(\"ACCURACY: \", accuracy_score(smart_y_seq_dos, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(smart_y_seq_dos, lstm_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DECISION TREE--------\n",
      "SMART ATTACK EVAL\n",
      "ACCURACY:  0.5969791022791535\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.81      0.73    100000\n",
      "         1.0       0.34      0.19      0.24     52074\n",
      "\n",
      "    accuracy                           0.60    152074\n",
      "   macro avg       0.50      0.50      0.48    152074\n",
      "weighted avg       0.55      0.60      0.56    152074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_preds = dt.predict(smart_X)\n",
    "\n",
    "print(\"-------DECISION TREE--------\")\n",
    "\n",
    "print(\"SMART ATTACK EVAL\")\n",
    "print(\"ACCURACY: \", accuracy_score(smart_y, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(smart_y, dt_preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
