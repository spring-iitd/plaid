{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e917863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score\n",
    "from joblib import load\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.colors import ListedColormap\n",
    "import tensorflow as tf\n",
    "\n",
    "data_path = '../Smart Attack Algorithm/data/Car Hacking Dataset/benign_data.csv'\n",
    "\n",
    "def hex_to_bin(hex_num):\n",
    "    \n",
    "    binary_value = bin(int(str(hex_num), 16))[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def int_to_bin(int_num):\n",
    "    \n",
    "    binary_value = bin(int_num)[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "hex_to_dec = lambda x: int(x, 16)\n",
    "dec_to_hex = lambda x : hex(int(x))[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87464536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    \n",
    "    columns = ['Timestamp','ID', 'DLC', 'Payload', 'label']\n",
    "    \n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    ##Replacing all NaNs with '00' \n",
    "    data = data.replace(np.NaN, '00')\n",
    "\n",
    "    data['ID'] = data['ID'].apply(hex_to_dec)\n",
    "    \n",
    "    data['Payload'] = data['Payload'].str.replace(' ', '')\n",
    "    data['Payload'] = data['Payload'].apply(hex_to_dec)\n",
    "    \n",
    "    data = data.assign(IAT=data['Timestamp'].diff().fillna(0))\n",
    "    data = data.drop(columns = ['Timestamp'], axis = 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f73cd727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Payload</th>\n",
       "      <th>IAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848</td>\n",
       "      <td>8</td>\n",
       "      <td>371692544708313250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704</td>\n",
       "      <td>8</td>\n",
       "      <td>1441151880758558720</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1072</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  DLC              Payload       IAT\n",
       "0   848    8   371692544708313250  0.000000\n",
       "1   704    8  1441151880758558720  0.000221\n",
       "2  1072    8                    0  0.000554\n",
       "3  1201    8                    0  0.000238\n",
       "4   497    8                    0  0.000248"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_data = read_data(data_path)\n",
    "normal_data.drop(columns = ['label'], inplace = True)\n",
    "normal_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675e5832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anwesh/opt/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test = train_test_split(normal_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler = load('ch_scaler.joblib')\n",
    "X_train = scaler.fit_transform(normal_data)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89a600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:27:12.156197: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-12 00:27:12.158147: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/30903 [..............................] - ETA: 1:45:17"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 00:27:12.919678: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-03-12 00:27:13.023021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30903/30903 [==============================] - 67s 2ms/step\n",
      "Training Loss:  1.0000050705461037\n"
     ]
    }
   ],
   "source": [
    "model = load_model('ae_ch.h5')\n",
    "X_train_pred = model.predict(X_train)\n",
    "\n",
    "print(\"Training Loss: \", mean_squared_error(X_train, X_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f2bdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_difference_error(X, X_recon):\n",
    "    # Calculate squared difference error between each sample of X and X_recon\n",
    "    squared_diff = np.square(X - X_recon)\n",
    "\n",
    "    return squared_diff\n",
    "\n",
    "training_losses = squared_difference_error(X_train, X_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b230150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 18:00:54.133793: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_735\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2024-03-11 18:00:54.503834: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-03-11 18:00:54.646004: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2497180000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 18:01:00.320482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12349/12361 [============================>.] - ETA: 0s - loss: 0.4805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 18:01:42.283882: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_15178\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12361/12361 [==============================] - 53s 3ms/step - loss: 0.4804 - val_loss: 0.2734\n",
      "Epoch 2/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2658 - val_loss: 0.2470\n",
      "Epoch 3/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2455 - val_loss: 0.2399\n",
      "Epoch 4/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2364 - val_loss: 0.2344\n",
      "Epoch 5/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2340 - val_loss: 0.2308\n",
      "Epoch 6/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2323 - val_loss: 0.2316\n",
      "Epoch 7/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2315 - val_loss: 0.2347\n",
      "Epoch 8/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2339 - val_loss: 0.2294\n",
      "Epoch 9/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2307 - val_loss: 0.2298\n",
      "Epoch 10/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2307 - val_loss: 0.2351\n",
      "Epoch 11/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2354 - val_loss: 0.2328\n",
      "Epoch 12/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2321 - val_loss: 0.2315\n",
      "Epoch 13/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2338 - val_loss: 0.2397\n",
      "Epoch 14/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2351 - val_loss: 0.2325\n",
      "Epoch 15/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2313 - val_loss: 0.2274\n",
      "Epoch 16/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2274 - val_loss: 0.2291\n",
      "Epoch 17/1000\n",
      "12361/12361 [==============================] - 39s 3ms/step - loss: 0.2306 - val_loss: 0.2310\n",
      "Epoch 18/1000\n",
      "12361/12361 [==============================] - 39s 3ms/step - loss: 0.2304 - val_loss: 0.2300\n",
      "Epoch 19/1000\n",
      "12361/12361 [==============================] - 39s 3ms/step - loss: 0.2311 - val_loss: 0.2307\n",
      "Epoch 20/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2265 - val_loss: 0.2262\n",
      "Epoch 21/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2283 - val_loss: 0.2302\n",
      "Epoch 22/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2341 - val_loss: 0.2393\n",
      "Epoch 23/1000\n",
      "12361/12361 [==============================] - 54s 4ms/step - loss: 0.2408 - val_loss: 0.2287\n",
      "Epoch 24/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2298 - val_loss: 0.2261\n",
      "Epoch 25/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2287 - val_loss: 0.2295\n",
      "Epoch 26/1000\n",
      "12361/12361 [==============================] - 40s 3ms/step - loss: 0.2302 - val_loss: 0.2306\n",
      "Epoch 27/1000\n",
      "12346/12361 [============================>.] - ETA: 0s - loss: 0.2330"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5999/4289562101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m history = model.fit(X_train, X_train, epochs=EPOCHS, batch_size=BATCH_SIZE, \n\u001b[0;32m---> 38\u001b[0;31m                     validation_data=(X_test, X_test), callbacks=[reduce_lr, early_stopper])\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# strat = MirroredStrategy()\n",
    "\n",
    "# EPOCHS = 1000\n",
    "# BATCH_SIZE = 32 * strat.num_replicas_in_sync\n",
    "# LOSS = 'mse'\n",
    "\n",
    "# # Define early stopping callback\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "#                               patience=20)\n",
    "\n",
    "# early_stopper = EarlyStopping(monitor='val_loss', patience=60, restore_best_weights=True)\n",
    "\n",
    "# input_dim = X_train.shape[1]\n",
    "\n",
    "\n",
    "# with strat.scope():\n",
    "#     model = Sequential()\n",
    "\n",
    "#     ##Encoder\n",
    "#     model.add(Dense(input_dim, input_shape=(input_dim, ), activation='relu'))\n",
    "#     model.add(Dense(3, activation='relu'))\n",
    "#     model.add(Dense(2, activation='relu'))\n",
    "\n",
    "#     ##Bottleneck\n",
    "#     model.add(Dense(1, activation='relu'))\n",
    "\n",
    "#     ##Decoder\n",
    "#     model.add(Dense(2, activation='relu'))\n",
    "#     model.add(Dense(3, activation='relu'))\n",
    "#     model.add(Dense(input_dim))\n",
    "    \n",
    " \n",
    "\n",
    "#     model.compile(optimizer='adam', loss=LOSS)\n",
    "\n",
    "# history = model.fit(X_train, X_train, epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
    "#                     validation_data=(X_test, X_test), callbacks=[reduce_lr, early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8090d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_labels(X, X_recon, threshold):\n",
    "    # Calculate squared error between each row of X and X_recon\n",
    "    squared_errors = np.mean(np.square(X - X_recon), axis=1)\n",
    "\n",
    "    # Assign labels based on threshold\n",
    "    labels = [0 if error < threshold else 1 for error in squared_errors]\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30d067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_hacking_df = pd.read_csv('../Smart Attack Algorithm/data/Car Hacking Dataset/preprocessed_car_hacking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e54bfc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Payload</th>\n",
       "      <th>IAT</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0316</td>\n",
       "      <td>8</td>\n",
       "      <td>052168092121006f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>018f</td>\n",
       "      <td>8</td>\n",
       "      <td>fe5b0000003c0000</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0260</td>\n",
       "      <td>8</td>\n",
       "      <td>19212230088e6d3a</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>02a0</td>\n",
       "      <td>8</td>\n",
       "      <td>64009a1d9702bd00</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0329</td>\n",
       "      <td>8</td>\n",
       "      <td>40bb7f1411200014</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp    ID  DLC           Payload       IAT  label\n",
       "0  1.478198e+09  0316    8  052168092121006f  0.000000      0\n",
       "1  1.478198e+09  018f    8  fe5b0000003c0000  0.000209      0\n",
       "2  1.478198e+09  0260    8  19212230088e6d3a  0.000228      0\n",
       "3  1.478198e+09  02a0    8  64009a1d9702bd00  0.000232      0\n",
       "4  1.478198e+09  0329    8  40bb7f1411200014  0.000237      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_hacking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a665ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_hacking_df.drop(columns = ['Timestamp'], inplace = True)\n",
    "\n",
    "car_hacking_df['ID'] = car_hacking_df['ID'].apply(hex_to_dec)\n",
    "car_hacking_df['Payload'] = car_hacking_df['Payload'].apply(hex_to_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b44ab461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'DLC', 'Payload', 'IAT', 'label'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_hacking_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7eab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_hacking_df.drop(columns = ['label'])\n",
    "y = car_hacking_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48f6f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81f262e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57278/57278 [==============================] - 143s 2ms/step\n",
      "=====================================\n",
      "Threshold: 0.1544637858073506\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.17013143276783887\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.2580062999329285\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.431669409703145\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.4895234007505207\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.48952362545757894\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 1.0849276809432622\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 1.1773809704151852\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 2.5345112944962325\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 3.9436125341044956\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n"
     ]
    }
   ],
   "source": [
    "def vary_thresholds(training_errors = training_losses, start = 0.5, end = 1, step = 0.05):\n",
    "\n",
    "    quantiles = np.arange(start, end, step)\n",
    "\n",
    "    thresholds = [np.quantile(training_errors, q) for q in quantiles]\n",
    "\n",
    "    X_val_recon = model.predict(X_val)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "\n",
    "        print(\"=====================================\")\n",
    "        print(f\"Threshold: {threshold}\")\n",
    "        \n",
    "        y_val_pred = assign_labels(X_val, X_val_recon, threshold)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy_score(y_val, y_val_pred)}\")\n",
    "\n",
    "        print(f\"F1 Score: {f1_score(y_val, y_val_pred)}\")\n",
    "\n",
    "        print(f\"Recall: {recall_score(y_val, y_val_pred)}\")\n",
    "\n",
    "        print(f\"Precision: {precision_score(y_val, y_val_pred)}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "vary_thresholds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fecfd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57278/57278 [==============================] - 143s 2ms/step\n",
      "=====================================\n",
      "Threshold: 0.007256824738672733\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.05709869276351965\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.05709869276351965\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.05709869276351965\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.05709869276351965\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.05709869276351965\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.09420508967874949\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.14095215568819047\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n",
      "=====================================\n",
      "Threshold: 0.14756799411701982\n",
      "Accuracy: 0.16046124006688908\n",
      "F1 Score: 0.276547349496378\n",
      "Recall: 1.0\n",
      "Precision: 0.16046124006688908\n"
     ]
    }
   ],
   "source": [
    "vary_thresholds(start = 0.05, end = 0.5, step = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1af91f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57278/57278 [==============================] - 119s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcf8a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = assign_labels(X_test, X_test_pred, 1.0000050705461037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a55eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16008306026670507\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92b313c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00   1539472\n",
      "           1       0.16      1.00      0.28    293414\n",
      "\n",
      "    accuracy                           0.16   1832886\n",
      "   macro avg       0.08      0.50      0.14   1832886\n",
      "weighted avg       0.03      0.16      0.04   1832886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \", classification_report(y_test, y_test_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
