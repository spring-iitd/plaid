{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5afccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, MultiHeadAttention, LayerNormalization, RepeatVector, LeakyReLU, Flatten, TimeDistributed, Add, Conv1D, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "from datetime import datetime\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304843cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 17:14:20.128756: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-04 17:14:20.130760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-08-04 17:14:22.060639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-08-04 17:14:22.062011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-08-04 17:14:22.062051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-04 17:14:22.066153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-04 17:14:22.066232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-08-04 17:14:22.071924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-04 17:14:22.072812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-04 17:14:22.076634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-04 17:14:22.080553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-08-04 17:14:22.087765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-08-04 17:14:22.093018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce60ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fuzzy_dataset.csv',\n",
       " 'normal_run_data.txt',\n",
       " 'gear_dataset.csv',\n",
       " '.DS_Store',\n",
       " 'RPM_dataset.csv',\n",
       " 'DoS_dataset.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../car_hacking_data/'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ae7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data_path = os.path.join(data_dir, \"normal_run_data.txt\")\n",
    "dos_data_path = os.path.join(data_dir, 'DoS_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696d8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_to_dec = lambda x: int(x, 16)\n",
    "\n",
    "## Since there are varying DLCs (2,5,6,8) in order to maintain data integrity\n",
    "## The data must be padded with 00s when DLC < 8\n",
    "\n",
    "def shift_columns(df):\n",
    "    \n",
    "    for dlc in [2,5,6]:\n",
    "\n",
    "        df.loc[df['dlc'] == dlc, df.columns[3:]] = df.loc[df['dlc'] == dlc, df.columns[3:]].shift(periods=8-dlc, axis='columns', fill_value='00')\n",
    "\n",
    "    return df\n",
    "\n",
    "def pad_with_zeros(string, desired_length=16):\n",
    "    if len(string) >= desired_length:\n",
    "        return string\n",
    "    else:\n",
    "        return string.zfill(desired_length)\n",
    "    \n",
    "def split_string_into_list(string):\n",
    "    # Initialize an empty list to store the result\n",
    "    result_list = []\n",
    "\n",
    "    # Iterate through the string with a step size of 2\n",
    "    for i in range(0, len(string), 2):\n",
    "        # Extract two characters at a time and add them to the result list\n",
    "        item = string[i:i+2]\n",
    "        result_list.append(item)\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112c9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_attack_data(data_path):\n",
    "    \n",
    "    columns = ['timestamp','can_id', 'dlc', 'data0', 'data1', 'data2', 'data3', 'data4', \n",
    "           'data5', 'data6', 'data7', 'flag']\n",
    "    \n",
    "    data = pd.read_csv(data_path, names = columns)\n",
    "\n",
    "    data = shift_columns(data)\n",
    "    \n",
    "    ##Replacing all NaNs with '00' \n",
    "    data = data.replace(np.NaN, '00')\n",
    "    \n",
    "    ##Joining all data columns to put all data in one column\n",
    "    data_cols = ['data0', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
    "    \n",
    "    ##The data column is in hexadecimal\n",
    "#     data['data'] = data[data_cols].apply(''.join, axis=1)\n",
    "#     data.drop(columns = data_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    ##Converting columns to decimal\n",
    "    data['can_id'] = data['can_id'].apply(hex_to_dec)\n",
    "    data[data_cols] = data[data_cols].astype(str)\n",
    "    \n",
    "    data.sort_values(by = ['timestamp'], inplace = True)\n",
    "    data = data.assign(IAT=data['timestamp'].diff().fillna(0))\n",
    "    data.drop(['timestamp'], inplace = True, axis = 1)\n",
    "    \n",
    "    data[data_cols] = data[data_cols].applymap(hex_to_dec)\n",
    "    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ff0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "ids = []\n",
    "dlcs = []\n",
    "data = []\n",
    "data_cols = ['data0', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
    "    \n",
    "# Read the data from the file\n",
    "with open(benign_data_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Extract information from each line\n",
    "        line = line.strip()\n",
    "        ts = line.split('Timestamp: ')[1].split(' ')[0]\n",
    "        can_id = line.split('ID: ')[1].split(' ')[0]\n",
    "        dlc = line.split('DLC: ')[1].split(' ')[0]\n",
    "        can_data = ''.join(line.split('DLC: ')[1].split(' ')[1:])\n",
    "        \n",
    "        can_data = pad_with_zeros(can_data)\n",
    "        data_split = split_string_into_list(can_data)\n",
    "               \n",
    "        #Converting Hexadecimal entries to decimal format\n",
    "        timestamps.append(float(ts))\n",
    "        ids.append(hex_to_dec(can_id))\n",
    "        dlcs.append(int(dlc))\n",
    "        data.append([hex_to_dec(hex_str) for hex_str in data_split])\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "# data_dict = {f\"data{i}\": col for i, col in enumerate(data_split)}\n",
    "        \n",
    "benign = pd.DataFrame({\n",
    "    'timestamp': timestamps,\n",
    "    'can_id': ids,\n",
    "    'dlc': dlcs})\n",
    "\n",
    "data = pd.DataFrame(data, columns = data_cols)\n",
    "\n",
    "benign_data = pd.concat([benign, data], axis=1)\n",
    "benign_data.sort_values(by = ['timestamp'], inplace = True)\n",
    "\n",
    "# # Creating IAT column\n",
    "benign_data= benign_data.assign(IAT=benign_data['timestamp'].diff().fillna(0))\n",
    "benign_data.drop(columns = ['timestamp'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46de4178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>can_id</th>\n",
       "      <th>dlc</th>\n",
       "      <th>data0</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>data4</th>\n",
       "      <th>data5</th>\n",
       "      <th>data6</th>\n",
       "      <th>data7</th>\n",
       "      <th>IAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>132</td>\n",
       "      <td>102</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1072</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   can_id  dlc  data0  data1  data2  data3  data4  data5  data6  data7  \\\n",
       "0     848    8      5     40    132    102    109      0      0    162   \n",
       "1     704    8     20      0      0      0      0      0      0      0   \n",
       "2    1072    8      0      0      0      0      0      0      0      0   \n",
       "3    1201    8      0      0      0      0      0      0      0      0   \n",
       "4     497    8      0      0      0      0      0      0      0      0   \n",
       "\n",
       "        IAT  \n",
       "0  0.000000  \n",
       "1  0.000221  \n",
       "2  0.000554  \n",
       "3  0.000238  \n",
       "4  0.000248  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cfe8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "dos_data = read_attack_data(dos_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11314214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>can_id</th>\n",
       "      <th>dlc</th>\n",
       "      <th>data0</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>data4</th>\n",
       "      <th>data5</th>\n",
       "      <th>data6</th>\n",
       "      <th>data7</th>\n",
       "      <th>flag</th>\n",
       "      <th>IAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>790</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>R</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>8</td>\n",
       "      <td>254</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>R</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>672</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>29</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>809</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>187</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>R</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   can_id  dlc  data0  data1  data2  data3  data4  data5  data6  data7 flag  \\\n",
       "0     790    8      5     33    104      9     33     33      0    111    R   \n",
       "1     399    8    254     91      0      0      0     60      0      0    R   \n",
       "2     608    8     25     33     34     48      8    142    109     58    R   \n",
       "3     672    8    100      0    154     29    151      2    189      0    R   \n",
       "4     809    8     64    187    127     20     17     32      0     20    R   \n",
       "\n",
       "        IAT  \n",
       "0  0.000000  \n",
       "1  0.000209  \n",
       "2  0.000228  \n",
       "3  0.000232  \n",
       "4  0.000237  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e58a23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dos_data.drop(['flag'], axis = 1)\n",
    "y_test = dos_data['flag'].replace({'R' : 0, 'T' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c97d0b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([3078250,  587521]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc164be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('first_run/scaler.sav')\n",
    "\n",
    "X_train = scaler.transform(benign_data.values)\n",
    "y_train = np.zeros(X_train.shape[0])\n",
    "\n",
    "X_test = scaler.transform(X_test.values)\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e27eb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencify(X, target, start, end, window):\n",
    "    \n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    start = start + window\n",
    "    if end is None:\n",
    "        end = len(X)\n",
    "        \n",
    "    for i in range(start, end+1):\n",
    "        indices = range(i - window, i)\n",
    "        X_seq.append(X[indices])\n",
    "        \n",
    "        # Check if there is at least one element with value 1 in the sequence\n",
    "        if any(target[j] == 1 for j in indices):\n",
    "            y_seq.append(1)\n",
    "        else:\n",
    "            y_seq.append(0)\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d00d2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_size = 10\n",
    "\n",
    "\n",
    "X_train_seq, y_train_seq = sequencify(X_train, y_train, start = 0, end = None, window = seq_size)\n",
    "X_test_seq, y_test_seq = sequencify(X_test, y_test, start = 0, end = None, window = seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a30b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 17:16:04.803388: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-04 17:16:04.877406: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-04 17:16:05.253655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-08-04 17:16:05.255016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-08-04 17:16:05.255059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-04 17:16:05.255100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-04 17:16:05.255123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-08-04 17:16:05.255143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-04 17:16:05.255165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-04 17:16:05.255183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-04 17:16:05.255202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-08-04 17:16:05.255221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-08-04 17:16:05.261937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-08-04 17:16:05.287257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-04 17:16:23.353944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-04 17:16:23.354004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-08-04 17:16:23.354041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2023-08-04 17:16:23.354049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2023-08-04 17:16:23.404490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)\n",
      "2023-08-04 17:16:23.448479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30132 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strat = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strat.scope():\n",
    "    model = load_model('first_run/ae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f77e328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 17:16:29.409840: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_10859\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2023-08-04 17:16:29.615901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-08-04 17:16:29.701742: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n",
      "2023-08-04 17:16:34.213047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "train_recon = model.predict(X_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64f5907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(988862, 10, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751ad7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(988862, 10, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05f854c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(y_true, y_pred):\n",
    "  \n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ff98497",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = calculate_mse(X_train_seq, train_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbc42813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252546720020174"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9f07b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 17:20:18.025211: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_44163\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    }
   ],
   "source": [
    "test_recon = model.predict(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38852cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_percentages = [x for x in range(50,105,5)]\n",
    "thresh_vals = [(x/100) * train_loss for x in thresh_percentages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f541d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_samples(sequencified_array, reconstructions, model, threshold):\n",
    "    num_samples, seq_size, num_features = sequencified_array.shape\n",
    "    \n",
    "    classification_labels = []\n",
    "    \n",
    "    for i in range(len(reconstructions)):\n",
    "        \n",
    "        sample = sequencified_array[i]\n",
    "        reconstructed_sample = reconstructions[i]\n",
    "        \n",
    "        loss = calculate_mse(sample, reconstructed_sample)\n",
    "        \n",
    "        if loss > threshold:\n",
    "            classification_labels.append(1)\n",
    "        else:\n",
    "            classification_labels.append(0)\n",
    "    \n",
    "    return np.array(classification_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "521b4837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 50\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00   2585834\n",
      "           1       0.27      0.89      0.41   1079928\n",
      "\n",
      "    accuracy                           0.26   3665762\n",
      "   macro avg       0.14      0.44      0.21   3665762\n",
      "weighted avg       0.08      0.26      0.12   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 55\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.00      0.00   2585834\n",
      "           1       0.25      0.81      0.39   1079928\n",
      "\n",
      "    accuracy                           0.24   3665762\n",
      "   macro avg       0.14      0.41      0.19   3665762\n",
      "weighted avg       0.09      0.24      0.12   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 60\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.01      0.02   2585834\n",
      "           1       0.24      0.73      0.36   1079928\n",
      "\n",
      "    accuracy                           0.22   3665762\n",
      "   macro avg       0.16      0.37      0.19   3665762\n",
      "weighted avg       0.13      0.22      0.12   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 65\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.04      0.07   2585834\n",
      "           1       0.23      0.67      0.34   1079928\n",
      "\n",
      "    accuracy                           0.23   3665762\n",
      "   macro avg       0.22      0.36      0.20   3665762\n",
      "weighted avg       0.22      0.23      0.15   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 70\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.10      0.16   2585834\n",
      "           1       0.23      0.63      0.33   1079928\n",
      "\n",
      "    accuracy                           0.26   3665762\n",
      "   macro avg       0.31      0.37      0.25   3665762\n",
      "weighted avg       0.35      0.26      0.21   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.20      0.29   2585834\n",
      "           1       0.24      0.60      0.34   1079928\n",
      "\n",
      "    accuracy                           0.32   3665762\n",
      "   macro avg       0.39      0.40      0.32   3665762\n",
      "weighted avg       0.46      0.32      0.31   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 80\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.32      0.43   2585834\n",
      "           1       0.26      0.58      0.36   1079928\n",
      "\n",
      "    accuracy                           0.40   3665762\n",
      "   macro avg       0.46      0.45      0.40   3665762\n",
      "weighted avg       0.54      0.40      0.41   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.55   2585834\n",
      "           1       0.30      0.56      0.39   1079928\n",
      "\n",
      "    accuracy                           0.48   3665762\n",
      "   macro avg       0.51      0.51      0.47   3665762\n",
      "weighted avg       0.59      0.48      0.50   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 90\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64   2585834\n",
      "           1       0.34      0.55      0.42   1079928\n",
      "\n",
      "    accuracy                           0.55   3665762\n",
      "   macro avg       0.54      0.55      0.53   3665762\n",
      "weighted avg       0.63      0.55      0.57   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.70   2585834\n",
      "           1       0.38      0.52      0.44   1079928\n",
      "\n",
      "    accuracy                           0.61   3665762\n",
      "   macro avg       0.57      0.59      0.57   3665762\n",
      "weighted avg       0.65      0.61      0.63   3665762\n",
      "\n",
      "---------x-------------\n",
      "Threshold: 100\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75   2585834\n",
      "           1       0.43      0.50      0.46   1079928\n",
      "\n",
      "    accuracy                           0.65   3665762\n",
      "   macro avg       0.60      0.61      0.60   3665762\n",
      "weighted avg       0.67      0.65      0.66   3665762\n",
      "\n",
      "---------x-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(thresh_vals)):\n",
    "    \n",
    "    y_pred = classify_samples(X_test_seq, test_recon, model, thresh_vals[i])\n",
    "    \n",
    "    print(\"Threshold:\", thresh_percentages[i])\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    \n",
    "    print(classification_report(y_test_seq, y_pred))\n",
    "    \n",
    "    print(\"---------x-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a36227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
