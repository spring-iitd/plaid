{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c263f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 06:36:32.320570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2754496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal_run_data.txt', 'DoS_dataset.csv', 'Fuzzy_dataset.csv', 'gear_dataset.csv', 'RPM_dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'car_hacking_data/'\n",
    "print(os.listdir(data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782ca2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_data_path = os.path.join(data_folder, 'RPM_dataset.csv')\n",
    "gear_data_path = os.path.join(data_folder, 'gear_dataset.csv')\n",
    "dos_data_path = os.path.join(data_folder, 'DoS_dataset.csv')\n",
    "fuzzy_data_path = os.path.join(data_folder, 'Fuzzy_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0536743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bin(hex_num):\n",
    "    \n",
    "    binary_value = bin(int(str(hex_num), 16))[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def int_to_bin(int_num):\n",
    "    \n",
    "    binary_value = bin(int_num)[2:]\n",
    "    \n",
    "    return binary_value\n",
    "\n",
    "def pad(value, length):\n",
    "    \n",
    "    curr_length = len(str(value))\n",
    "    \n",
    "    zeros = '0' * (length - curr_length)\n",
    "    \n",
    "    return zeros + value\n",
    "\n",
    "hex_to_dec = lambda x: int(x, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f374e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since there are varying DLCs (2,5,6,8) in order to maintain data integrity\n",
    "## The data must be padded with 00s when DLC < 8\n",
    "\n",
    "def shift_columns(df):\n",
    "    \n",
    "    for dlc in [2,5,6]:\n",
    "\n",
    "        df.loc[df['dlc'] == dlc, df.columns[3:]] = df.loc[df['dlc'] == dlc, df.columns[3:]].shift(periods=8-dlc, axis='columns', fill_value='00')\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece69fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_attack_data(data_path):\n",
    "    \n",
    "    columns = ['timestamp','can_id', 'dlc', 'data0', 'data1', 'data2', 'data3', 'data4', \n",
    "           'data5', 'data6', 'data7', 'flag']\n",
    "    \n",
    "    data = pd.read_csv(data_path, names = columns)\n",
    "\n",
    "    data = shift_columns(data)\n",
    "    \n",
    "    ##Replacing all NaNs with '00' \n",
    "    data = data.replace(np.NaN, '00')\n",
    "    \n",
    "    ##Joining all data columns to put all data in one column\n",
    "    data_cols = ['data0', 'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7']\n",
    "    \n",
    "    ##The data column is in hexadecimal\n",
    "    data['data'] = data[data_cols].apply(''.join, axis=1)\n",
    "    data.drop(columns = data_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    ##Converting columns to decimal\n",
    "    data['can_id'] = data['can_id'].apply(hex_to_dec)\n",
    "    data['data'] = data['data'].apply(hex_to_dec)\n",
    "    \n",
    "    data = data.assign(IAT=data['timestamp'].diff().fillna(0))\n",
    "    \n",
    "    return data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4c4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data_path = os.path.join(data_folder, 'normal_run_data.txt')\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "timestamps = []\n",
    "ids = []\n",
    "dlcs = []\n",
    "data = []\n",
    "\n",
    "# Read the data from the file\n",
    "with open(normal_data_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Extract information from each line\n",
    "        line = line.strip()\n",
    "        ts = line.split('Timestamp: ')[1].split(' ')[0]\n",
    "        can_id = line.split('ID: ')[1].split(' ')[0]\n",
    "        dlc = line.split('DLC: ')[1].split(' ')[0]\n",
    "        can_data = ''.join(line.split('DLC: ')[1].split(' ')[1:])\n",
    "        \n",
    "        #Converting Hexadecimal entries to decimal format\n",
    "        timestamps.append(float(ts))\n",
    "        ids.append(hex_to_dec(can_id))\n",
    "        dlcs.append(int(dlc))\n",
    "        data.append(hex_to_dec(can_data))\n",
    "        \n",
    "normal_data = pd.DataFrame({\n",
    "    'timestamp': timestamps,\n",
    "    'can_id': ids,\n",
    "    'dlc': dlcs,\n",
    "    'data': data\n",
    "})\n",
    "\n",
    "normal_data.sort_values(by = ['timestamp'], inplace = True)\n",
    "\n",
    "# Creating IAT column\n",
    "normal_data = normal_data.assign(IAT=normal_data['timestamp'].diff().fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd57425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_data = read_attack_data(rpm_data_path)\n",
    "gear_data = read_attack_data(gear_data_path)\n",
    "dos_data = read_attack_data(dos_data_path)\n",
    "fuzzy_data = read_attack_data(fuzzy_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d518900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>can_id</th>\n",
       "      <th>dlc</th>\n",
       "      <th>flag</th>\n",
       "      <th>data</th>\n",
       "      <th>IAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>790</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>369972507834318965</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>399</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>18319235909263556608</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>608</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>1811047593997725247</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>672</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>6917673190735133952</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>809</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>15904600708710662164</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  can_id  dlc flag                  data       IAT\n",
       "0  1.478191e+09     790    8    R    369972507834318965  0.000000\n",
       "1  1.478191e+09     399    8    R  18319235909263556608  0.000239\n",
       "2  1.478191e+09     608    8    R   1811047593997725247  0.000227\n",
       "3  1.478191e+09     672    8    R   6917673190735133952  0.000235\n",
       "4  1.478191e+09     809    8    R  15904600708710662164  0.000228"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1c4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining labels\n",
    "\n",
    "# Normal -> 0\n",
    "# DOS -> 1\n",
    "# Fuzzy -> 2\n",
    "# Gear -> 3\n",
    "\n",
    "\n",
    "\n",
    "gear_data['flag'].replace({'R' : 0, 'T' : 3}, inplace = True)\n",
    "dos_data['flag'].replace({'R' : 0, 'T' : 1}, inplace = True)\n",
    "fuzzy_data['flag'].replace({'R' : 0, 'T' : 2}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc619c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data['flag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe4f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining datasets\n",
    "merged_df = pd.concat([gear_data, dos_data, fuzzy_data, normal_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30499da",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sort_values(by = ['timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c067cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(columns = ['timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "227bd3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create a sequencified dataset for LSTM moodel\n",
    "def sequencify(dataset, target, start, end, window):\n",
    "  \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    start = start + window \n",
    "    if end is None:\n",
    "        end = len(dataset)\n",
    "        \n",
    "    for i in range(start, end+1):\n",
    "        indices = range(i-window, i) \n",
    "        X.append(dataset[indices])\n",
    "        \n",
    "        indicey = i -1\n",
    "        y.append(target[indicey])\n",
    "\t\t\t\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dd2cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df[['can_id', 'dlc', 'data', 'IAT']].values\n",
    "y = merged_df['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d639454",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq, y_seq = sequencify(dataset = X, target = y, window = 10, start = 0, end = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0add975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since we are predicting the label for the current sequence, we can shuffle during train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce07e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_seq, y_seq, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc5ae4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([7881764,  411890,  343787,  418203]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_seq, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5473520",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing dataset\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "mean = X_train_seq.mean(axis=0)\n",
    "std = X_train_seq.std(axis=0)\n",
    "\n",
    "X_train_seq -= mean\n",
    "X_train_seq /= std\n",
    "X_test_seq -= mean\n",
    "X_test_seq /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ff82a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9055650, 4)\n",
      "(9055644, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c48e17b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 06:54:43.145452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-07 06:54:43.148557: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef538c09ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-07 06:54:43.148583: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-07-07 06:54:43.154711: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-07 06:54:43.350242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-07-07 06:54:43.518255: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885/885 [==============================] - 8s 6ms/step - loss: 0.2681 - accuracy: 0.8864 - val_loss: 0.2061 - val_accuracy: 0.9361\n",
      "Epoch 2/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1890 - accuracy: 0.9299 - val_loss: 0.1736 - val_accuracy: 0.9486\n",
      "Epoch 3/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1601 - accuracy: 0.9406 - val_loss: 0.1486 - val_accuracy: 0.9421\n",
      "Epoch 4/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1375 - accuracy: 0.9458 - val_loss: 0.1259 - val_accuracy: 0.9427\n",
      "Epoch 5/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1187 - accuracy: 0.9492 - val_loss: 0.1126 - val_accuracy: 0.9424\n",
      "Epoch 6/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1092 - accuracy: 0.9529 - val_loss: 0.1057 - val_accuracy: 0.9783\n",
      "Epoch 7/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1020 - accuracy: 0.9594 - val_loss: 0.0981 - val_accuracy: 0.9818\n",
      "Epoch 8/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0947 - accuracy: 0.9686 - val_loss: 0.0906 - val_accuracy: 0.9866\n",
      "Epoch 9/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0881 - accuracy: 0.9732 - val_loss: 0.0849 - val_accuracy: 0.9514\n",
      "Epoch 10/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0818 - accuracy: 0.9818 - val_loss: 0.0775 - val_accuracy: 0.9886\n",
      "Epoch 11/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0747 - accuracy: 0.9867 - val_loss: 0.0714 - val_accuracy: 0.9893\n",
      "Epoch 12/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0678 - accuracy: 0.9886 - val_loss: 0.0635 - val_accuracy: 0.9897\n",
      "Epoch 13/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0616 - accuracy: 0.9894 - val_loss: 0.0575 - val_accuracy: 0.9906\n",
      "Epoch 14/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0565 - accuracy: 0.9900 - val_loss: 0.0541 - val_accuracy: 0.9910\n",
      "Epoch 15/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0512 - accuracy: 0.9905 - val_loss: 0.0486 - val_accuracy: 0.9907\n",
      "Epoch 16/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0466 - accuracy: 0.9914 - val_loss: 0.0466 - val_accuracy: 0.9910\n",
      "Epoch 17/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0475 - accuracy: 0.9910 - val_loss: 0.0452 - val_accuracy: 0.9921\n",
      "Epoch 18/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0442 - accuracy: 0.9909 - val_loss: 0.0413 - val_accuracy: 0.9918\n",
      "Epoch 19/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0378 - accuracy: 0.9922 - val_loss: 0.0392 - val_accuracy: 0.9913\n",
      "Epoch 20/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0526 - accuracy: 0.9906 - val_loss: 0.0473 - val_accuracy: 0.9921\n",
      "Epoch 21/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0442 - accuracy: 0.9924 - val_loss: 0.0420 - val_accuracy: 0.9920\n",
      "Epoch 22/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0422 - accuracy: 0.9922 - val_loss: 0.0396 - val_accuracy: 0.9921\n",
      "Epoch 23/100\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0377 - accuracy: 0.9930 - val_loss: 0.0374 - val_accuracy: 0.9929\n",
      "Epoch 24/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0356 - accuracy: 0.9926 - val_loss: 0.0344 - val_accuracy: 0.9933\n",
      "Epoch 25/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0335 - accuracy: 0.9930 - val_loss: 0.0327 - val_accuracy: 0.9933\n",
      "Epoch 26/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0547 - accuracy: 0.9910 - val_loss: 0.0568 - val_accuracy: 0.9914\n",
      "Epoch 27/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0547 - accuracy: 0.9918 - val_loss: 0.0487 - val_accuracy: 0.9926\n",
      "Epoch 28/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0475 - accuracy: 0.9931 - val_loss: 0.0566 - val_accuracy: 0.9921\n",
      "Epoch 29/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0448 - accuracy: 0.9931 - val_loss: 0.0429 - val_accuracy: 0.9929\n",
      "Epoch 30/100\n",
      "885/885 [==============================] - 5s 5ms/step - loss: 0.0422 - accuracy: 0.9932 - val_loss: 0.0401 - val_accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "\n",
    "print(\"-----MLP-------\")\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Input(shape = (4)))\n",
    "mlp.add(Dense(128, activation = 'relu'))\n",
    "mlp.add(Dense(128, activation = 'relu'))\n",
    "mlp.add(Dense(4))\n",
    "\n",
    "mlp.compile(optimizer='adam',\n",
    "                loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "mlp_hist = mlp.fit(X_train, y_train, epochs=100, callbacks = [es], validation_split=0.2, batch_size = 8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4949b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----MLP-------\n",
      "474/474 [==============================] - 1s 2ms/step\n",
      "ACCURACY:  0.9933694821481301\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00   3378118\n",
      "           1       1.00      1.00      1.00    176044\n",
      "           2       0.99      0.87      0.93    147797\n",
      "           3       0.98      1.00      0.99    179035\n",
      "\n",
      "    accuracy                           0.99   3880994\n",
      "   macro avg       0.99      0.97      0.98   3880994\n",
      "weighted avg       0.99      0.99      0.99   3880994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##MLP\n",
    "print(\"-----MLP-------\")\n",
    "\n",
    "mlp_preds = mlp.predict(X_test, batch_size = 8196)\n",
    "mlp_preds = mlp_preds.argmax(axis = 1)\n",
    "\n",
    "print(\"ACCURACY: \", accuracy_score(y_test, mlp_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test, mlp_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd63706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/1000\n",
      "884/884 [==============================] - 25s 26ms/step - loss: 0.2168 - accuracy: 0.9259 - val_loss: 0.1374 - val_accuracy: 0.9502\n",
      "Epoch 2/1000\n",
      "884/884 [==============================] - 22s 24ms/step - loss: 0.1101 - accuracy: 0.9573 - val_loss: 0.0960 - val_accuracy: 0.9626\n",
      "Epoch 3/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0906 - accuracy: 0.9664 - val_loss: 0.0801 - val_accuracy: 0.9712\n",
      "Epoch 4/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0770 - accuracy: 0.9728 - val_loss: 0.0695 - val_accuracy: 0.9766\n",
      "Epoch 5/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 0.0628 - val_accuracy: 0.9795\n",
      "Epoch 6/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0620 - accuracy: 0.9793 - val_loss: 0.0590 - val_accuracy: 0.9809\n",
      "Epoch 7/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.0566 - val_accuracy: 0.9815\n",
      "Epoch 8/1000\n",
      "884/884 [==============================] - 23s 25ms/step - loss: 0.0566 - accuracy: 0.9813 - val_loss: 0.0542 - val_accuracy: 0.9825\n",
      "Epoch 9/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0550 - accuracy: 0.9818 - val_loss: 0.0563 - val_accuracy: 0.9821\n",
      "Epoch 10/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.0528 - val_accuracy: 0.9829\n",
      "Epoch 11/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.0526 - val_accuracy: 0.9831\n",
      "Epoch 12/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0505 - accuracy: 0.9834 - val_loss: 0.0492 - val_accuracy: 0.9841\n",
      "Epoch 13/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 0.0491 - val_accuracy: 0.9839\n",
      "Epoch 14/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 0.0473 - val_accuracy: 0.9848\n",
      "Epoch 15/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0472 - accuracy: 0.9845 - val_loss: 0.0456 - val_accuracy: 0.9851\n",
      "Epoch 16/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0465 - accuracy: 0.9847 - val_loss: 0.0472 - val_accuracy: 0.9845\n",
      "Epoch 17/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0464 - accuracy: 0.9847 - val_loss: 0.0457 - val_accuracy: 0.9850\n",
      "Epoch 18/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 0.0453 - val_accuracy: 0.9851\n",
      "Epoch 19/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0447 - val_accuracy: 0.9853\n",
      "Epoch 20/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0438 - accuracy: 0.9855 - val_loss: 0.0448 - val_accuracy: 0.9852\n",
      "Epoch 21/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0433 - accuracy: 0.9856 - val_loss: 0.0424 - val_accuracy: 0.9860\n",
      "Epoch 22/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.0432 - val_accuracy: 0.9858\n",
      "Epoch 23/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0423 - accuracy: 0.9859 - val_loss: 0.0430 - val_accuracy: 0.9859\n",
      "Epoch 24/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.0425 - val_accuracy: 0.9859\n",
      "Epoch 25/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 26/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 27/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0402 - accuracy: 0.9865 - val_loss: 0.0399 - val_accuracy: 0.9864\n",
      "Epoch 28/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0400 - accuracy: 0.9866 - val_loss: 0.0409 - val_accuracy: 0.9863\n",
      "Epoch 29/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0394 - accuracy: 0.9868 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 30/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 0.0399 - val_accuracy: 0.9862\n",
      "Epoch 31/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 32/1000\n",
      "884/884 [==============================] - 20s 23ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.0387 - val_accuracy: 0.9867\n",
      "Epoch 33/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 0.0386 - val_accuracy: 0.9877\n",
      "Epoch 34/1000\n",
      "884/884 [==============================] - 20s 23ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.0383 - val_accuracy: 0.9866\n",
      "Epoch 35/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0368 - accuracy: 0.9876 - val_loss: 0.0372 - val_accuracy: 0.9873\n",
      "Epoch 36/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.0377 - val_accuracy: 0.9869\n",
      "Epoch 37/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 0.0370 - val_accuracy: 0.9881\n",
      "Epoch 38/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 0.0369 - val_accuracy: 0.9881\n",
      "Epoch 39/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.0367 - val_accuracy: 0.9889\n",
      "Epoch 40/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.0347 - val_accuracy: 0.9886\n",
      "Epoch 41/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0349 - val_accuracy: 0.9891\n",
      "Epoch 42/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.0358 - val_accuracy: 0.9890\n",
      "Epoch 43/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.0348 - val_accuracy: 0.9882\n",
      "Epoch 44/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.0354 - val_accuracy: 0.9889\n",
      "Epoch 45/1000\n",
      "884/884 [==============================] - 20s 23ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0343 - val_accuracy: 0.9884\n",
      "Epoch 46/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.0333 - val_accuracy: 0.9889\n",
      "Epoch 47/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0333 - val_accuracy: 0.9890\n",
      "Epoch 48/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.0327 - val_accuracy: 0.9896\n",
      "Epoch 49/1000\n",
      "884/884 [==============================] - 21s 23ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.0331 - val_accuracy: 0.9894\n",
      "Epoch 50/1000\n",
      "884/884 [==============================] - 21s 23ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0330 - val_accuracy: 0.9892\n",
      "Epoch 51/1000\n",
      "884/884 [==============================] - 20s 23ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.0323 - val_accuracy: 0.9896\n",
      "Epoch 52/1000\n",
      "884/884 [==============================] - 20s 22ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.0369 - val_accuracy: 0.9878\n",
      "Epoch 53/1000\n",
      "884/884 [==============================] - 20s 22ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.0323 - val_accuracy: 0.9892\n",
      "Epoch 54/1000\n",
      "884/884 [==============================] - 20s 22ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.0327 - val_accuracy: 0.9895\n",
      "Epoch 55/1000\n",
      "884/884 [==============================] - 20s 22ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 0.0323 - val_accuracy: 0.9896\n",
      "Epoch 56/1000\n",
      "884/884 [==============================] - 21s 23ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.0322 - val_accuracy: 0.9893\n",
      "Epoch 57/1000\n",
      "884/884 [==============================] - 20s 23ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 0.0319 - val_accuracy: 0.9897\n",
      "Epoch 58/1000\n",
      "884/884 [==============================] - 20s 22ms/step - loss: 0.0302 - accuracy: 0.9901 - val_loss: 0.0311 - val_accuracy: 0.9901\n",
      "Epoch 59/1000\n",
      "884/884 [==============================] - 20s 22ms/step - loss: 0.0302 - accuracy: 0.9901 - val_loss: 0.0310 - val_accuracy: 0.9902\n",
      "Epoch 60/1000\n",
      "884/884 [==============================] - 20s 23ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0310 - val_accuracy: 0.9897\n",
      "Epoch 61/1000\n",
      "884/884 [==============================] - 20s 23ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.0304 - val_accuracy: 0.9904\n",
      "Epoch 62/1000\n",
      "884/884 [==============================] - 22s 25ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0316 - val_accuracy: 0.9893\n",
      "Epoch 63/1000\n",
      "884/884 [==============================] - 22s 24ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0314 - val_accuracy: 0.9893\n",
      "Epoch 64/1000\n",
      "884/884 [==============================] - 23s 26ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0306 - val_accuracy: 0.9902\n",
      "Epoch 65/1000\n",
      "884/884 [==============================] - 21s 24ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.0308 - val_accuracy: 0.9903\n",
      "Epoch 66/1000\n",
      "884/884 [==============================] - 21s 23ms/step - loss: 0.0610 - accuracy: 0.9904 - val_loss: 0.0304 - val_accuracy: 0.9902\n"
     ]
    }
   ],
   "source": [
    "##LSTM\n",
    "\n",
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(Input(shape = X_train_seq.shape[1:]))\n",
    "lstm.add(LSTM(128, activation = 'relu'))\n",
    "lstm.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "lstm.compile(\n",
    "    loss = SparseCategoricalCrossentropy(from_logits = False),\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "lstm_hist = lstm.fit(X_train_seq, y_train_seq, batch_size = 8196, validation_split = 0.2,\n",
    "        callbacks = [es], epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c858e3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LSTM-------\n",
      "948/948 [==============================] - 6s 6ms/step\n",
      "ACCURACY:  0.9904449662470229\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99   3378251\n",
      "           1       0.97      0.99      0.98    175631\n",
      "           2       0.93      0.88      0.91    148060\n",
      "           3       0.99      0.99      0.99    179049\n",
      "\n",
      "    accuracy                           0.99   3880991\n",
      "   macro avg       0.97      0.97      0.97   3880991\n",
      "weighted avg       0.99      0.99      0.99   3880991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-----LSTM-------\")\n",
    "\n",
    "lstm_preds = lstm.predict(X_test_seq, batch_size=4096)\n",
    "lstm_preds = lstm_preds.argmax(axis = 1)\n",
    "\n",
    "print(\"ACCURACY: \", accuracy_score(y_test_seq, lstm_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test_seq, lstm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7db49be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------XGBOOST-------\n",
      "ACCURACY:  0.998768614432282\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3378118\n",
      "           1       1.00      1.00      1.00    176044\n",
      "           2       1.00      1.00      1.00    147797\n",
      "           3       0.98      1.00      0.99    179035\n",
      "\n",
      "    accuracy                           1.00   3880994\n",
      "   macro avg       0.99      1.00      1.00   3880994\n",
      "weighted avg       1.00      1.00      1.00   3880994\n",
      "\n",
      "-------DECISION TREE--------\n",
      "ACCURACY:  0.9546075051906805\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97   3378118\n",
      "           1       1.00      1.00      1.00    176044\n",
      "           2       0.69      0.49      0.57    147797\n",
      "           3       0.72      1.00      0.84    179035\n",
      "\n",
      "    accuracy                           0.95   3880994\n",
      "   macro avg       0.85      0.86      0.85   3880994\n",
      "weighted avg       0.96      0.95      0.95   3880994\n",
      "\n",
      "-------RANDOM FOREST-------\n",
      "ACCURACY:  0.9737134352694181\n",
      "CLASSIFICATION REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99   3378118\n",
      "           1       1.00      1.00      1.00    176044\n",
      "           2       1.00      0.34      0.51    147797\n",
      "           3       0.98      1.00      0.99    179035\n",
      "\n",
      "    accuracy                           0.97   3880994\n",
      "   macro avg       0.99      0.83      0.87   3880994\n",
      "weighted avg       0.97      0.97      0.97   3880994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## XGBOOST\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_preds = xgb.predict(X_test)\n",
    "\n",
    "print(\"-------XGBOOST-------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test, xgb_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test, xgb_preds))\n",
    "\n",
    "\n",
    "## DECISION TREE\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth = 4)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_preds = dt.predict(X_test)\n",
    "\n",
    "print(\"-------DECISION TREE--------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test, dt_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test, dt_preds))\n",
    "\n",
    "\n",
    "## RANDOM FOREST\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "print(\"-------RANDOM FOREST-------\")\n",
    "print(\"ACCURACY: \", accuracy_score(y_test, rf_preds))\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test, rf_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
