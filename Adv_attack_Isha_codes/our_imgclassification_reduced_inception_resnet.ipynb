{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import timm\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../to anwesh/selected_images\"  # Path to the image directory\n",
    "metadata_path = \"../to anwesh/selected_images.txt\"  # Path to the metadata JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): Path to the directory with images.\n",
    "            label_file (str): Path to the file containing labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load labels from the text file\n",
    "        self.image_labels = {}\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                image_name, label = line.strip().split(\":\")\n",
    "                label = int(label.strip())\n",
    "                self.image_labels[image_name] = label\n",
    "\n",
    "        # List of image filenames\n",
    "        self.image_files = list(self.image_labels.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples\"\"\"\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Fetch an image and its label\"\"\"\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # Get label\n",
    "        label = self.image_labels[img_name]\n",
    "        \n",
    "        # Apply transformation if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((29, 29)),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OurDataset(image_dir=image_dir, label_file=metadata_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history including loss and accuracy curves.\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_losses'], label='Train Loss')\n",
    "    plt.plot(history['test_losses'], label='Test Loss')\n",
    "    plt.title('Training and Testing Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_accuracies'], label='Train Accuracy')\n",
    "    plt.plot(history['test_accuracies'], label='Test Accuracy')\n",
    "    plt.title('Training and Testing Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"Evaluate the model on the test set and print detailed metrics.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc='Evaluating'):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_acc = accuracy_score(all_targets, all_preds)\n",
    "    \n",
    "    print(\"\\nTest Set Evaluation:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResNetABlock(nn.Module):\n",
    "    def __init__(self, in_channels, scale=0.17):\n",
    "        super(InceptionResNetABlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.branch0 = nn.Conv2d(in_channels, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.conv_up = nn.Conv2d(96, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch0 = self.branch0(x)\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        mixed = torch.cat([branch0, branch1, branch2], dim=1)\n",
    "        up = self.conv_up(mixed)\n",
    "        return F.relu(x + self.scale * up)\n",
    "\n",
    "# Inception-ResNet Model\n",
    "class InceptionResNetV1(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(InceptionResNetV1, self).__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
    "            nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.inception_a = InceptionResNetABlock(in_channels=128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_a(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = InceptionResNetV1(num_classes=2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        pred = output.argmax(dim=1, keepdim=False)  # Get the predicted class\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        if batch_idx % 10_000 == 0:  # Adjust this to suit your dataset size\n",
    "            accuracy = 100. * correct / total\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] \"\n",
    "                  f\"Loss: {loss.item():.6f} Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Print overall training loss and accuracy for the epoch\n",
    "    overall_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch} Summary: Average Loss: {running_loss / len(train_loader):.6f}, \"\n",
    "          f\"Accuracy: {overall_accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=False)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "    recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    \n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\\n\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(all_targets), yticklabels=np.unique(all_targets))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2230] Loss: 0.686739 Accuracy: 56.25%\n",
      "Epoch 1 Summary: Average Loss: 0.693923, Accuracy: 50.36%\n",
      "Train Epoch: 2 [0/2230] Loss: 0.690166 Accuracy: 51.56%\n",
      "Epoch 2 Summary: Average Loss: 0.687041, Accuracy: 55.07%\n",
      "Train Epoch: 3 [0/2230] Loss: 0.680443 Accuracy: 70.31%\n",
      "Epoch 3 Summary: Average Loss: 0.661807, Accuracy: 67.17%\n",
      "Train Epoch: 4 [0/2230] Loss: 0.609284 Accuracy: 93.75%\n",
      "Epoch 4 Summary: Average Loss: 0.531855, Accuracy: 86.68%\n",
      "Train Epoch: 5 [0/2230] Loss: 0.562815 Accuracy: 70.31%\n",
      "Epoch 5 Summary: Average Loss: 0.378595, Accuracy: 87.62%\n",
      "Train Epoch: 6 [0/2230] Loss: 0.338793 Accuracy: 90.62%\n",
      "Epoch 6 Summary: Average Loss: 0.324406, Accuracy: 89.01%\n",
      "Train Epoch: 7 [0/2230] Loss: 0.440210 Accuracy: 81.25%\n",
      "Epoch 7 Summary: Average Loss: 0.306494, Accuracy: 89.10%\n",
      "Train Epoch: 8 [0/2230] Loss: 0.383518 Accuracy: 89.06%\n",
      "Epoch 8 Summary: Average Loss: 0.307873, Accuracy: 89.24%\n",
      "Train Epoch: 9 [0/2230] Loss: 0.220806 Accuracy: 93.75%\n",
      "Epoch 9 Summary: Average Loss: 0.280702, Accuracy: 89.73%\n",
      "Train Epoch: 10 [0/2230] Loss: 0.264484 Accuracy: 89.06%\n",
      "Epoch 10 Summary: Average Loss: 0.265211, Accuracy: 89.64%\n",
      "Train Epoch: 11 [0/2230] Loss: 0.288306 Accuracy: 85.94%\n",
      "Epoch 11 Summary: Average Loss: 0.239015, Accuracy: 90.54%\n",
      "Train Epoch: 12 [0/2230] Loss: 0.289563 Accuracy: 87.50%\n",
      "Epoch 12 Summary: Average Loss: 0.236104, Accuracy: 91.03%\n",
      "Train Epoch: 13 [0/2230] Loss: 0.168491 Accuracy: 96.88%\n",
      "Epoch 13 Summary: Average Loss: 0.238524, Accuracy: 91.43%\n",
      "Train Epoch: 14 [0/2230] Loss: 0.401439 Accuracy: 87.50%\n",
      "Epoch 14 Summary: Average Loss: 0.222719, Accuracy: 91.88%\n",
      "Train Epoch: 15 [0/2230] Loss: 0.098852 Accuracy: 95.31%\n",
      "Epoch 15 Summary: Average Loss: 0.208939, Accuracy: 92.29%\n",
      "Train Epoch: 16 [0/2230] Loss: 0.168570 Accuracy: 93.75%\n",
      "Epoch 16 Summary: Average Loss: 0.195573, Accuracy: 92.60%\n",
      "Train Epoch: 17 [0/2230] Loss: 0.210678 Accuracy: 93.75%\n",
      "Epoch 17 Summary: Average Loss: 0.183851, Accuracy: 93.27%\n",
      "Train Epoch: 18 [0/2230] Loss: 0.107745 Accuracy: 96.88%\n",
      "Epoch 18 Summary: Average Loss: 0.168725, Accuracy: 94.30%\n",
      "Train Epoch: 19 [0/2230] Loss: 0.196850 Accuracy: 93.75%\n",
      "Epoch 19 Summary: Average Loss: 0.173195, Accuracy: 94.17%\n",
      "Train Epoch: 20 [0/2230] Loss: 0.092887 Accuracy: 96.88%\n",
      "Epoch 20 Summary: Average Loss: 0.157154, Accuracy: 94.71%\n",
      "Train Epoch: 21 [0/2230] Loss: 0.249223 Accuracy: 89.06%\n",
      "Epoch 21 Summary: Average Loss: 0.179375, Accuracy: 94.26%\n",
      "Train Epoch: 22 [0/2230] Loss: 0.141962 Accuracy: 92.19%\n",
      "Epoch 22 Summary: Average Loss: 0.162070, Accuracy: 94.35%\n",
      "Train Epoch: 23 [0/2230] Loss: 0.060106 Accuracy: 100.00%\n",
      "Epoch 23 Summary: Average Loss: 0.148643, Accuracy: 95.25%\n",
      "Train Epoch: 24 [0/2230] Loss: 0.124048 Accuracy: 95.31%\n",
      "Epoch 24 Summary: Average Loss: 0.127039, Accuracy: 95.74%\n",
      "Train Epoch: 25 [0/2230] Loss: 0.156017 Accuracy: 93.75%\n",
      "Epoch 25 Summary: Average Loss: 0.134504, Accuracy: 95.02%\n",
      "Train Epoch: 26 [0/2230] Loss: 0.176617 Accuracy: 92.19%\n",
      "Epoch 26 Summary: Average Loss: 0.152761, Accuracy: 94.84%\n",
      "Train Epoch: 27 [0/2230] Loss: 0.094327 Accuracy: 95.31%\n",
      "Epoch 27 Summary: Average Loss: 0.123151, Accuracy: 96.19%\n",
      "Train Epoch: 28 [0/2230] Loss: 0.201407 Accuracy: 95.31%\n",
      "Epoch 28 Summary: Average Loss: 0.110184, Accuracy: 96.77%\n",
      "Train Epoch: 29 [0/2230] Loss: 0.101938 Accuracy: 96.88%\n",
      "Epoch 29 Summary: Average Loss: 0.155267, Accuracy: 95.07%\n",
      "Train Epoch: 30 [0/2230] Loss: 0.070918 Accuracy: 96.88%\n",
      "Epoch 30 Summary: Average Loss: 0.136203, Accuracy: 95.29%\n",
      "Train Epoch: 31 [0/2230] Loss: 0.284767 Accuracy: 95.31%\n",
      "Epoch 31 Summary: Average Loss: 0.109007, Accuracy: 97.09%\n",
      "Train Epoch: 32 [0/2230] Loss: 0.134869 Accuracy: 95.31%\n",
      "Epoch 32 Summary: Average Loss: 0.096603, Accuracy: 97.26%\n",
      "Train Epoch: 33 [0/2230] Loss: 0.041516 Accuracy: 100.00%\n",
      "Epoch 33 Summary: Average Loss: 0.090173, Accuracy: 97.53%\n",
      "Train Epoch: 34 [0/2230] Loss: 0.225541 Accuracy: 95.31%\n",
      "Epoch 34 Summary: Average Loss: 0.096585, Accuracy: 97.17%\n",
      "Train Epoch: 35 [0/2230] Loss: 0.137324 Accuracy: 93.75%\n",
      "Epoch 35 Summary: Average Loss: 0.101355, Accuracy: 96.91%\n",
      "Train Epoch: 36 [0/2230] Loss: 0.031996 Accuracy: 98.44%\n",
      "Epoch 36 Summary: Average Loss: 0.113264, Accuracy: 96.68%\n",
      "Train Epoch: 37 [0/2230] Loss: 0.042226 Accuracy: 96.88%\n",
      "Epoch 37 Summary: Average Loss: 0.098065, Accuracy: 97.13%\n",
      "Train Epoch: 38 [0/2230] Loss: 0.078044 Accuracy: 96.88%\n",
      "Epoch 38 Summary: Average Loss: 0.081934, Accuracy: 97.62%\n",
      "Train Epoch: 39 [0/2230] Loss: 0.044545 Accuracy: 98.44%\n",
      "Epoch 39 Summary: Average Loss: 0.079453, Accuracy: 97.76%\n",
      "Train Epoch: 40 [0/2230] Loss: 0.025912 Accuracy: 98.44%\n",
      "Epoch 40 Summary: Average Loss: 0.086187, Accuracy: 97.53%\n",
      "Train Epoch: 41 [0/2230] Loss: 0.017994 Accuracy: 100.00%\n",
      "Epoch 41 Summary: Average Loss: 0.121088, Accuracy: 95.96%\n",
      "Train Epoch: 42 [0/2230] Loss: 0.033998 Accuracy: 100.00%\n",
      "Epoch 42 Summary: Average Loss: 0.092644, Accuracy: 97.09%\n",
      "Train Epoch: 43 [0/2230] Loss: 0.028291 Accuracy: 100.00%\n",
      "Epoch 43 Summary: Average Loss: 0.079116, Accuracy: 97.94%\n",
      "Train Epoch: 44 [0/2230] Loss: 0.041103 Accuracy: 96.88%\n",
      "Epoch 44 Summary: Average Loss: 0.108119, Accuracy: 96.73%\n",
      "Train Epoch: 45 [0/2230] Loss: 0.070504 Accuracy: 96.88%\n",
      "Epoch 45 Summary: Average Loss: 0.105324, Accuracy: 96.55%\n",
      "Train Epoch: 46 [0/2230] Loss: 0.036859 Accuracy: 98.44%\n",
      "Epoch 46 Summary: Average Loss: 0.081121, Accuracy: 97.62%\n",
      "Train Epoch: 47 [0/2230] Loss: 0.015820 Accuracy: 100.00%\n",
      "Epoch 47 Summary: Average Loss: 0.070264, Accuracy: 98.25%\n",
      "Train Epoch: 48 [0/2230] Loss: 0.094600 Accuracy: 96.88%\n",
      "Epoch 48 Summary: Average Loss: 0.071460, Accuracy: 98.25%\n",
      "Train Epoch: 49 [0/2230] Loss: 0.031408 Accuracy: 100.00%\n",
      "Epoch 49 Summary: Average Loss: 0.064280, Accuracy: 98.30%\n",
      "Train Epoch: 50 [0/2230] Loss: 0.052097 Accuracy: 96.88%\n",
      "Epoch 50 Summary: Average Loss: 0.063297, Accuracy: 98.39%\n",
      "Train Epoch: 51 [0/2230] Loss: 0.034320 Accuracy: 98.44%\n",
      "Epoch 51 Summary: Average Loss: 0.079261, Accuracy: 97.89%\n",
      "Train Epoch: 52 [0/2230] Loss: 0.014542 Accuracy: 100.00%\n",
      "Epoch 52 Summary: Average Loss: 0.068848, Accuracy: 98.07%\n",
      "Train Epoch: 53 [0/2230] Loss: 0.115561 Accuracy: 96.88%\n",
      "Epoch 53 Summary: Average Loss: 0.057248, Accuracy: 98.52%\n",
      "Train Epoch: 54 [0/2230] Loss: 0.018386 Accuracy: 100.00%\n",
      "Epoch 54 Summary: Average Loss: 0.062760, Accuracy: 98.34%\n",
      "Train Epoch: 55 [0/2230] Loss: 0.033906 Accuracy: 100.00%\n",
      "Epoch 55 Summary: Average Loss: 0.059083, Accuracy: 98.74%\n",
      "Train Epoch: 56 [0/2230] Loss: 0.011767 Accuracy: 100.00%\n",
      "Epoch 56 Summary: Average Loss: 0.077965, Accuracy: 98.07%\n",
      "Train Epoch: 57 [0/2230] Loss: 0.051727 Accuracy: 98.44%\n",
      "Epoch 57 Summary: Average Loss: 0.067124, Accuracy: 98.12%\n",
      "Train Epoch: 58 [0/2230] Loss: 0.023794 Accuracy: 100.00%\n",
      "Epoch 58 Summary: Average Loss: 0.072594, Accuracy: 97.98%\n",
      "Train Epoch: 59 [0/2230] Loss: 0.179502 Accuracy: 93.75%\n",
      "Epoch 59 Summary: Average Loss: 0.069779, Accuracy: 98.34%\n",
      "Train Epoch: 60 [0/2230] Loss: 0.034108 Accuracy: 100.00%\n",
      "Epoch 60 Summary: Average Loss: 0.068153, Accuracy: 98.07%\n",
      "Train Epoch: 61 [0/2230] Loss: 0.108012 Accuracy: 95.31%\n",
      "Epoch 61 Summary: Average Loss: 0.058278, Accuracy: 98.65%\n",
      "Train Epoch: 62 [0/2230] Loss: 0.087582 Accuracy: 98.44%\n",
      "Epoch 62 Summary: Average Loss: 0.050051, Accuracy: 98.65%\n",
      "Train Epoch: 63 [0/2230] Loss: 0.005866 Accuracy: 100.00%\n",
      "Epoch 63 Summary: Average Loss: 0.065424, Accuracy: 98.21%\n",
      "Train Epoch: 64 [0/2230] Loss: 0.275014 Accuracy: 95.31%\n",
      "Epoch 64 Summary: Average Loss: 0.068792, Accuracy: 98.16%\n",
      "Train Epoch: 65 [0/2230] Loss: 0.054133 Accuracy: 96.88%\n",
      "Epoch 65 Summary: Average Loss: 0.053059, Accuracy: 98.61%\n",
      "Train Epoch: 66 [0/2230] Loss: 0.008824 Accuracy: 100.00%\n",
      "Epoch 66 Summary: Average Loss: 0.057615, Accuracy: 98.25%\n",
      "Train Epoch: 67 [0/2230] Loss: 0.011238 Accuracy: 100.00%\n",
      "Epoch 67 Summary: Average Loss: 0.071503, Accuracy: 97.89%\n",
      "Train Epoch: 68 [0/2230] Loss: 0.016306 Accuracy: 100.00%\n",
      "Epoch 68 Summary: Average Loss: 0.050783, Accuracy: 98.83%\n",
      "Train Epoch: 69 [0/2230] Loss: 0.051739 Accuracy: 98.44%\n",
      "Epoch 69 Summary: Average Loss: 0.070732, Accuracy: 97.89%\n",
      "Train Epoch: 70 [0/2230] Loss: 0.031415 Accuracy: 98.44%\n",
      "Epoch 70 Summary: Average Loss: 0.082335, Accuracy: 97.49%\n",
      "Train Epoch: 71 [0/2230] Loss: 0.028355 Accuracy: 98.44%\n",
      "Epoch 71 Summary: Average Loss: 0.087583, Accuracy: 97.40%\n",
      "Train Epoch: 72 [0/2230] Loss: 0.024383 Accuracy: 98.44%\n",
      "Epoch 72 Summary: Average Loss: 0.057180, Accuracy: 98.52%\n",
      "Train Epoch: 73 [0/2230] Loss: 0.207723 Accuracy: 93.75%\n",
      "Epoch 73 Summary: Average Loss: 0.049446, Accuracy: 98.83%\n",
      "Train Epoch: 74 [0/2230] Loss: 0.009723 Accuracy: 100.00%\n",
      "Epoch 74 Summary: Average Loss: 0.046840, Accuracy: 98.79%\n",
      "Train Epoch: 75 [0/2230] Loss: 0.164356 Accuracy: 96.88%\n",
      "Epoch 75 Summary: Average Loss: 0.055862, Accuracy: 98.30%\n",
      "Train Epoch: 76 [0/2230] Loss: 0.058523 Accuracy: 98.44%\n",
      "Epoch 76 Summary: Average Loss: 0.052169, Accuracy: 98.57%\n",
      "Train Epoch: 77 [0/2230] Loss: 0.012663 Accuracy: 100.00%\n",
      "Epoch 77 Summary: Average Loss: 0.047148, Accuracy: 98.70%\n",
      "Train Epoch: 78 [0/2230] Loss: 0.037090 Accuracy: 98.44%\n",
      "Epoch 78 Summary: Average Loss: 0.052361, Accuracy: 98.48%\n",
      "Train Epoch: 79 [0/2230] Loss: 0.007158 Accuracy: 100.00%\n",
      "Epoch 79 Summary: Average Loss: 0.049803, Accuracy: 98.48%\n",
      "Train Epoch: 80 [0/2230] Loss: 0.034545 Accuracy: 98.44%\n",
      "Epoch 80 Summary: Average Loss: 0.052633, Accuracy: 98.52%\n",
      "Train Epoch: 81 [0/2230] Loss: 0.011440 Accuracy: 100.00%\n",
      "Epoch 81 Summary: Average Loss: 0.042022, Accuracy: 99.01%\n",
      "Train Epoch: 82 [0/2230] Loss: 0.029761 Accuracy: 100.00%\n",
      "Epoch 82 Summary: Average Loss: 0.081826, Accuracy: 97.67%\n",
      "Train Epoch: 83 [0/2230] Loss: 0.070476 Accuracy: 98.44%\n",
      "Epoch 83 Summary: Average Loss: 0.081255, Accuracy: 97.31%\n",
      "Train Epoch: 84 [0/2230] Loss: 0.016963 Accuracy: 100.00%\n",
      "Epoch 84 Summary: Average Loss: 0.042249, Accuracy: 98.97%\n",
      "Train Epoch: 85 [0/2230] Loss: 0.006600 Accuracy: 100.00%\n",
      "Epoch 85 Summary: Average Loss: 0.041946, Accuracy: 99.01%\n",
      "Train Epoch: 86 [0/2230] Loss: 0.074641 Accuracy: 98.44%\n",
      "Epoch 86 Summary: Average Loss: 0.052159, Accuracy: 98.61%\n",
      "Train Epoch: 87 [0/2230] Loss: 0.049791 Accuracy: 98.44%\n",
      "Epoch 87 Summary: Average Loss: 0.059276, Accuracy: 98.65%\n",
      "Train Epoch: 88 [0/2230] Loss: 0.087491 Accuracy: 95.31%\n",
      "Epoch 88 Summary: Average Loss: 0.048244, Accuracy: 98.65%\n",
      "Train Epoch: 89 [0/2230] Loss: 0.022123 Accuracy: 98.44%\n",
      "Epoch 89 Summary: Average Loss: 0.051700, Accuracy: 98.83%\n",
      "Train Epoch: 90 [0/2230] Loss: 0.028943 Accuracy: 100.00%\n",
      "Epoch 90 Summary: Average Loss: 0.063024, Accuracy: 98.43%\n",
      "Train Epoch: 91 [0/2230] Loss: 0.046340 Accuracy: 98.44%\n",
      "Epoch 91 Summary: Average Loss: 0.052255, Accuracy: 98.57%\n",
      "Train Epoch: 92 [0/2230] Loss: 0.010268 Accuracy: 100.00%\n",
      "Epoch 92 Summary: Average Loss: 0.059326, Accuracy: 98.39%\n",
      "Train Epoch: 93 [0/2230] Loss: 0.027299 Accuracy: 100.00%\n",
      "Epoch 93 Summary: Average Loss: 0.044861, Accuracy: 98.92%\n",
      "Train Epoch: 94 [0/2230] Loss: 0.009567 Accuracy: 100.00%\n",
      "Epoch 94 Summary: Average Loss: 0.074859, Accuracy: 97.76%\n",
      "Train Epoch: 95 [0/2230] Loss: 0.059421 Accuracy: 96.88%\n",
      "Epoch 95 Summary: Average Loss: 0.066628, Accuracy: 98.07%\n",
      "Train Epoch: 96 [0/2230] Loss: 0.021106 Accuracy: 98.44%\n",
      "Epoch 96 Summary: Average Loss: 0.042528, Accuracy: 98.79%\n",
      "Train Epoch: 97 [0/2230] Loss: 0.010175 Accuracy: 100.00%\n",
      "Epoch 97 Summary: Average Loss: 0.039972, Accuracy: 98.88%\n",
      "Train Epoch: 98 [0/2230] Loss: 0.013945 Accuracy: 100.00%\n",
      "Epoch 98 Summary: Average Loss: 0.038210, Accuracy: 99.01%\n",
      "Train Epoch: 99 [0/2230] Loss: 0.009694 Accuracy: 100.00%\n",
      "Epoch 99 Summary: Average Loss: 0.035549, Accuracy: 99.15%\n",
      "Train Epoch: 100 [0/2230] Loss: 0.002831 Accuracy: 100.00%\n",
      "Epoch 100 Summary: Average Loss: 0.044344, Accuracy: 98.83%\n",
      "Train Epoch: 101 [0/2230] Loss: 0.022391 Accuracy: 100.00%\n",
      "Epoch 101 Summary: Average Loss: 0.056070, Accuracy: 98.57%\n",
      "Train Epoch: 102 [0/2230] Loss: 0.010238 Accuracy: 100.00%\n",
      "Epoch 102 Summary: Average Loss: 0.041149, Accuracy: 98.79%\n",
      "Train Epoch: 103 [0/2230] Loss: 0.069362 Accuracy: 98.44%\n",
      "Epoch 103 Summary: Average Loss: 0.045322, Accuracy: 98.74%\n",
      "Train Epoch: 104 [0/2230] Loss: 0.027750 Accuracy: 98.44%\n",
      "Epoch 104 Summary: Average Loss: 0.046318, Accuracy: 98.52%\n",
      "Train Epoch: 105 [0/2230] Loss: 0.034260 Accuracy: 98.44%\n",
      "Epoch 105 Summary: Average Loss: 0.046844, Accuracy: 98.83%\n",
      "Train Epoch: 106 [0/2230] Loss: 0.045414 Accuracy: 98.44%\n",
      "Epoch 106 Summary: Average Loss: 0.039287, Accuracy: 99.01%\n",
      "Train Epoch: 107 [0/2230] Loss: 0.127572 Accuracy: 96.88%\n",
      "Epoch 107 Summary: Average Loss: 0.039838, Accuracy: 99.06%\n",
      "Train Epoch: 108 [0/2230] Loss: 0.010460 Accuracy: 100.00%\n",
      "Epoch 108 Summary: Average Loss: 0.038888, Accuracy: 99.01%\n",
      "Train Epoch: 109 [0/2230] Loss: 0.006995 Accuracy: 100.00%\n",
      "Epoch 109 Summary: Average Loss: 0.037342, Accuracy: 99.15%\n",
      "Train Epoch: 110 [0/2230] Loss: 0.023134 Accuracy: 100.00%\n",
      "Epoch 110 Summary: Average Loss: 0.040978, Accuracy: 98.88%\n",
      "Train Epoch: 111 [0/2230] Loss: 0.013984 Accuracy: 100.00%\n",
      "Epoch 111 Summary: Average Loss: 0.054999, Accuracy: 98.61%\n",
      "Train Epoch: 112 [0/2230] Loss: 0.037694 Accuracy: 98.44%\n",
      "Epoch 112 Summary: Average Loss: 0.039858, Accuracy: 98.88%\n",
      "Train Epoch: 113 [0/2230] Loss: 0.002496 Accuracy: 100.00%\n",
      "Epoch 113 Summary: Average Loss: 0.038694, Accuracy: 98.92%\n",
      "Train Epoch: 114 [0/2230] Loss: 0.061238 Accuracy: 98.44%\n",
      "Epoch 114 Summary: Average Loss: 0.043727, Accuracy: 98.97%\n",
      "Train Epoch: 115 [0/2230] Loss: 0.008316 Accuracy: 100.00%\n",
      "Epoch 115 Summary: Average Loss: 0.036936, Accuracy: 99.06%\n",
      "Train Epoch: 116 [0/2230] Loss: 0.002644 Accuracy: 100.00%\n",
      "Epoch 116 Summary: Average Loss: 0.042893, Accuracy: 98.79%\n",
      "Train Epoch: 117 [0/2230] Loss: 0.008312 Accuracy: 100.00%\n",
      "Epoch 117 Summary: Average Loss: 0.036708, Accuracy: 99.15%\n",
      "Train Epoch: 118 [0/2230] Loss: 0.003544 Accuracy: 100.00%\n",
      "Epoch 118 Summary: Average Loss: 0.035597, Accuracy: 99.15%\n",
      "Train Epoch: 119 [0/2230] Loss: 0.011552 Accuracy: 100.00%\n",
      "Epoch 119 Summary: Average Loss: 0.035101, Accuracy: 99.19%\n",
      "Train Epoch: 120 [0/2230] Loss: 0.030983 Accuracy: 98.44%\n",
      "Epoch 120 Summary: Average Loss: 0.038811, Accuracy: 99.10%\n",
      "Train Epoch: 121 [0/2230] Loss: 0.003673 Accuracy: 100.00%\n",
      "Epoch 121 Summary: Average Loss: 0.037181, Accuracy: 99.01%\n",
      "Train Epoch: 122 [0/2230] Loss: 0.095748 Accuracy: 96.88%\n",
      "Epoch 122 Summary: Average Loss: 0.062135, Accuracy: 98.25%\n",
      "Train Epoch: 123 [0/2230] Loss: 0.064694 Accuracy: 96.88%\n",
      "Epoch 123 Summary: Average Loss: 0.060020, Accuracy: 98.48%\n",
      "Train Epoch: 124 [0/2230] Loss: 0.016360 Accuracy: 100.00%\n",
      "Epoch 124 Summary: Average Loss: 0.049413, Accuracy: 98.48%\n",
      "Train Epoch: 125 [0/2230] Loss: 0.016239 Accuracy: 100.00%\n",
      "Epoch 125 Summary: Average Loss: 0.049398, Accuracy: 98.70%\n",
      "Train Epoch: 126 [0/2230] Loss: 0.019509 Accuracy: 100.00%\n",
      "Epoch 126 Summary: Average Loss: 0.048189, Accuracy: 98.57%\n",
      "Train Epoch: 127 [0/2230] Loss: 0.122956 Accuracy: 96.88%\n",
      "Epoch 127 Summary: Average Loss: 0.051795, Accuracy: 98.57%\n",
      "Train Epoch: 128 [0/2230] Loss: 0.017222 Accuracy: 100.00%\n",
      "Epoch 128 Summary: Average Loss: 0.046903, Accuracy: 98.57%\n",
      "Train Epoch: 129 [0/2230] Loss: 0.055431 Accuracy: 98.44%\n",
      "Epoch 129 Summary: Average Loss: 0.069182, Accuracy: 97.80%\n",
      "Train Epoch: 130 [0/2230] Loss: 0.046108 Accuracy: 98.44%\n",
      "Epoch 130 Summary: Average Loss: 0.049525, Accuracy: 98.48%\n",
      "Train Epoch: 131 [0/2230] Loss: 0.036032 Accuracy: 96.88%\n",
      "Epoch 131 Summary: Average Loss: 0.035608, Accuracy: 99.01%\n",
      "Train Epoch: 132 [0/2230] Loss: 0.031185 Accuracy: 98.44%\n",
      "Epoch 132 Summary: Average Loss: 0.043579, Accuracy: 98.74%\n",
      "Train Epoch: 133 [0/2230] Loss: 0.121388 Accuracy: 96.88%\n",
      "Epoch 133 Summary: Average Loss: 0.045455, Accuracy: 98.83%\n",
      "Train Epoch: 134 [0/2230] Loss: 0.025851 Accuracy: 98.44%\n",
      "Epoch 134 Summary: Average Loss: 0.049803, Accuracy: 98.52%\n",
      "Train Epoch: 135 [0/2230] Loss: 0.028576 Accuracy: 98.44%\n",
      "Epoch 135 Summary: Average Loss: 0.034890, Accuracy: 99.19%\n",
      "Train Epoch: 136 [0/2230] Loss: 0.076707 Accuracy: 98.44%\n",
      "Epoch 136 Summary: Average Loss: 0.034356, Accuracy: 99.01%\n",
      "Train Epoch: 137 [0/2230] Loss: 0.010247 Accuracy: 100.00%\n",
      "Epoch 137 Summary: Average Loss: 0.037793, Accuracy: 98.97%\n",
      "Train Epoch: 138 [0/2230] Loss: 0.004673 Accuracy: 100.00%\n",
      "Epoch 138 Summary: Average Loss: 0.031927, Accuracy: 99.15%\n",
      "Train Epoch: 139 [0/2230] Loss: 0.106210 Accuracy: 98.44%\n",
      "Epoch 139 Summary: Average Loss: 0.036253, Accuracy: 98.92%\n",
      "Train Epoch: 140 [0/2230] Loss: 0.012262 Accuracy: 100.00%\n",
      "Epoch 140 Summary: Average Loss: 0.041315, Accuracy: 98.97%\n",
      "Train Epoch: 141 [0/2230] Loss: 0.006719 Accuracy: 100.00%\n",
      "Epoch 141 Summary: Average Loss: 0.045431, Accuracy: 98.92%\n",
      "Train Epoch: 142 [0/2230] Loss: 0.011882 Accuracy: 100.00%\n",
      "Epoch 142 Summary: Average Loss: 0.038547, Accuracy: 99.06%\n",
      "Train Epoch: 143 [0/2230] Loss: 0.005062 Accuracy: 100.00%\n",
      "Epoch 143 Summary: Average Loss: 0.040034, Accuracy: 98.97%\n",
      "Train Epoch: 144 [0/2230] Loss: 0.016044 Accuracy: 100.00%\n",
      "Epoch 144 Summary: Average Loss: 0.034275, Accuracy: 99.15%\n",
      "Train Epoch: 145 [0/2230] Loss: 0.010440 Accuracy: 100.00%\n",
      "Epoch 145 Summary: Average Loss: 0.035062, Accuracy: 99.10%\n",
      "Train Epoch: 146 [0/2230] Loss: 0.002343 Accuracy: 100.00%\n",
      "Epoch 146 Summary: Average Loss: 0.033318, Accuracy: 98.97%\n",
      "Train Epoch: 147 [0/2230] Loss: 0.001003 Accuracy: 100.00%\n",
      "Epoch 147 Summary: Average Loss: 0.038548, Accuracy: 99.10%\n",
      "Train Epoch: 148 [0/2230] Loss: 0.008555 Accuracy: 100.00%\n",
      "Epoch 148 Summary: Average Loss: 0.029661, Accuracy: 99.24%\n",
      "Train Epoch: 149 [0/2230] Loss: 0.049386 Accuracy: 98.44%\n",
      "Epoch 149 Summary: Average Loss: 0.033719, Accuracy: 99.19%\n",
      "Train Epoch: 150 [0/2230] Loss: 0.025227 Accuracy: 100.00%\n",
      "Epoch 150 Summary: Average Loss: 0.040770, Accuracy: 99.01%\n",
      "Train Epoch: 151 [0/2230] Loss: 0.014208 Accuracy: 100.00%\n",
      "Epoch 151 Summary: Average Loss: 0.040849, Accuracy: 98.88%\n",
      "Train Epoch: 152 [0/2230] Loss: 0.014899 Accuracy: 100.00%\n",
      "Epoch 152 Summary: Average Loss: 0.038110, Accuracy: 98.92%\n",
      "Train Epoch: 153 [0/2230] Loss: 0.013759 Accuracy: 100.00%\n",
      "Epoch 153 Summary: Average Loss: 0.036229, Accuracy: 98.88%\n",
      "Train Epoch: 154 [0/2230] Loss: 0.025999 Accuracy: 98.44%\n",
      "Epoch 154 Summary: Average Loss: 0.056295, Accuracy: 98.16%\n",
      "Train Epoch: 155 [0/2230] Loss: 0.014002 Accuracy: 100.00%\n",
      "Epoch 155 Summary: Average Loss: 0.036982, Accuracy: 99.10%\n",
      "Train Epoch: 156 [0/2230] Loss: 0.015018 Accuracy: 100.00%\n",
      "Epoch 156 Summary: Average Loss: 0.044402, Accuracy: 98.92%\n",
      "Train Epoch: 157 [0/2230] Loss: 0.033731 Accuracy: 98.44%\n",
      "Epoch 157 Summary: Average Loss: 0.042545, Accuracy: 98.88%\n",
      "Train Epoch: 158 [0/2230] Loss: 0.136451 Accuracy: 98.44%\n",
      "Epoch 158 Summary: Average Loss: 0.067971, Accuracy: 98.03%\n",
      "Train Epoch: 159 [0/2230] Loss: 0.011744 Accuracy: 100.00%\n",
      "Epoch 159 Summary: Average Loss: 0.038415, Accuracy: 98.92%\n",
      "Train Epoch: 160 [0/2230] Loss: 0.077814 Accuracy: 98.44%\n",
      "Epoch 160 Summary: Average Loss: 0.036568, Accuracy: 99.15%\n",
      "Train Epoch: 161 [0/2230] Loss: 0.115035 Accuracy: 98.44%\n",
      "Epoch 161 Summary: Average Loss: 0.034424, Accuracy: 99.28%\n",
      "Train Epoch: 162 [0/2230] Loss: 0.068180 Accuracy: 98.44%\n",
      "Epoch 162 Summary: Average Loss: 0.039571, Accuracy: 98.88%\n",
      "Train Epoch: 163 [0/2230] Loss: 0.009077 Accuracy: 100.00%\n",
      "Epoch 163 Summary: Average Loss: 0.037758, Accuracy: 99.10%\n",
      "Train Epoch: 164 [0/2230] Loss: 0.026909 Accuracy: 100.00%\n",
      "Epoch 164 Summary: Average Loss: 0.035745, Accuracy: 98.79%\n",
      "Train Epoch: 165 [0/2230] Loss: 0.036005 Accuracy: 98.44%\n",
      "Epoch 165 Summary: Average Loss: 0.041827, Accuracy: 98.97%\n",
      "Train Epoch: 166 [0/2230] Loss: 0.121410 Accuracy: 95.31%\n",
      "Epoch 166 Summary: Average Loss: 0.037084, Accuracy: 99.06%\n",
      "Train Epoch: 167 [0/2230] Loss: 0.035694 Accuracy: 98.44%\n",
      "Epoch 167 Summary: Average Loss: 0.034339, Accuracy: 99.19%\n",
      "Train Epoch: 168 [0/2230] Loss: 0.013644 Accuracy: 100.00%\n",
      "Epoch 168 Summary: Average Loss: 0.033729, Accuracy: 99.19%\n",
      "Train Epoch: 169 [0/2230] Loss: 0.005306 Accuracy: 100.00%\n",
      "Epoch 169 Summary: Average Loss: 0.030673, Accuracy: 99.24%\n",
      "Train Epoch: 170 [0/2230] Loss: 0.057650 Accuracy: 98.44%\n",
      "Epoch 170 Summary: Average Loss: 0.036786, Accuracy: 99.01%\n",
      "Train Epoch: 171 [0/2230] Loss: 0.008970 Accuracy: 100.00%\n",
      "Epoch 171 Summary: Average Loss: 0.043571, Accuracy: 98.70%\n",
      "Train Epoch: 172 [0/2230] Loss: 0.137526 Accuracy: 95.31%\n",
      "Epoch 172 Summary: Average Loss: 0.047903, Accuracy: 98.70%\n",
      "Train Epoch: 173 [0/2230] Loss: 0.015409 Accuracy: 100.00%\n",
      "Epoch 173 Summary: Average Loss: 0.035307, Accuracy: 99.10%\n",
      "Train Epoch: 174 [0/2230] Loss: 0.024494 Accuracy: 98.44%\n",
      "Epoch 174 Summary: Average Loss: 0.036144, Accuracy: 98.97%\n",
      "Train Epoch: 175 [0/2230] Loss: 0.010186 Accuracy: 100.00%\n",
      "Epoch 175 Summary: Average Loss: 0.031616, Accuracy: 99.28%\n",
      "Train Epoch: 176 [0/2230] Loss: 0.063890 Accuracy: 98.44%\n",
      "Epoch 176 Summary: Average Loss: 0.035304, Accuracy: 98.97%\n",
      "Train Epoch: 177 [0/2230] Loss: 0.009052 Accuracy: 100.00%\n",
      "Epoch 177 Summary: Average Loss: 0.043014, Accuracy: 98.97%\n",
      "Train Epoch: 178 [0/2230] Loss: 0.162519 Accuracy: 96.88%\n",
      "Epoch 178 Summary: Average Loss: 0.033384, Accuracy: 99.15%\n",
      "Train Epoch: 179 [0/2230] Loss: 0.032806 Accuracy: 98.44%\n",
      "Epoch 179 Summary: Average Loss: 0.042910, Accuracy: 98.97%\n",
      "Train Epoch: 180 [0/2230] Loss: 0.021414 Accuracy: 100.00%\n",
      "Epoch 180 Summary: Average Loss: 0.039144, Accuracy: 98.97%\n",
      "Train Epoch: 181 [0/2230] Loss: 0.009599 Accuracy: 100.00%\n",
      "Epoch 181 Summary: Average Loss: 0.034440, Accuracy: 99.15%\n",
      "Train Epoch: 182 [0/2230] Loss: 0.069084 Accuracy: 95.31%\n",
      "Epoch 182 Summary: Average Loss: 0.040725, Accuracy: 98.74%\n",
      "Train Epoch: 183 [0/2230] Loss: 0.125334 Accuracy: 98.44%\n",
      "Epoch 183 Summary: Average Loss: 0.034399, Accuracy: 99.15%\n",
      "Train Epoch: 184 [0/2230] Loss: 0.041889 Accuracy: 96.88%\n",
      "Epoch 184 Summary: Average Loss: 0.029616, Accuracy: 99.24%\n",
      "Train Epoch: 185 [0/2230] Loss: 0.013614 Accuracy: 100.00%\n",
      "Epoch 185 Summary: Average Loss: 0.030334, Accuracy: 99.10%\n",
      "Train Epoch: 186 [0/2230] Loss: 0.028496 Accuracy: 98.44%\n",
      "Epoch 186 Summary: Average Loss: 0.038462, Accuracy: 98.97%\n",
      "Train Epoch: 187 [0/2230] Loss: 0.001315 Accuracy: 100.00%\n",
      "Epoch 187 Summary: Average Loss: 0.036835, Accuracy: 99.06%\n",
      "Train Epoch: 188 [0/2230] Loss: 0.045612 Accuracy: 98.44%\n",
      "Epoch 188 Summary: Average Loss: 0.032415, Accuracy: 99.33%\n",
      "Train Epoch: 189 [0/2230] Loss: 0.004579 Accuracy: 100.00%\n",
      "Epoch 189 Summary: Average Loss: 0.028844, Accuracy: 99.28%\n",
      "Train Epoch: 190 [0/2230] Loss: 0.033054 Accuracy: 98.44%\n",
      "Epoch 190 Summary: Average Loss: 0.037102, Accuracy: 98.92%\n",
      "Train Epoch: 191 [0/2230] Loss: 0.006663 Accuracy: 100.00%\n",
      "Epoch 191 Summary: Average Loss: 0.043294, Accuracy: 98.79%\n",
      "Train Epoch: 192 [0/2230] Loss: 0.009749 Accuracy: 100.00%\n",
      "Epoch 192 Summary: Average Loss: 0.036717, Accuracy: 98.92%\n",
      "Train Epoch: 193 [0/2230] Loss: 0.018703 Accuracy: 98.44%\n",
      "Epoch 193 Summary: Average Loss: 0.032803, Accuracy: 99.10%\n",
      "Train Epoch: 194 [0/2230] Loss: 0.007442 Accuracy: 100.00%\n",
      "Epoch 194 Summary: Average Loss: 0.038296, Accuracy: 98.70%\n",
      "Train Epoch: 195 [0/2230] Loss: 0.034181 Accuracy: 98.44%\n",
      "Epoch 195 Summary: Average Loss: 0.054933, Accuracy: 98.34%\n",
      "Train Epoch: 196 [0/2230] Loss: 0.016445 Accuracy: 100.00%\n",
      "Epoch 196 Summary: Average Loss: 0.033978, Accuracy: 99.15%\n",
      "Train Epoch: 197 [0/2230] Loss: 0.006270 Accuracy: 100.00%\n",
      "Epoch 197 Summary: Average Loss: 0.028580, Accuracy: 99.15%\n",
      "Train Epoch: 198 [0/2230] Loss: 0.005093 Accuracy: 100.00%\n",
      "Epoch 198 Summary: Average Loss: 0.027567, Accuracy: 99.33%\n",
      "Train Epoch: 199 [0/2230] Loss: 0.011886 Accuracy: 100.00%\n",
      "Epoch 199 Summary: Average Loss: 0.029227, Accuracy: 99.24%\n",
      "Train Epoch: 200 [0/2230] Loss: 0.027684 Accuracy: 100.00%\n",
      "Epoch 200 Summary: Average Loss: 0.031784, Accuracy: 99.10%\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = InceptionResNetV1(num_classes=2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# model.load_state_dict(torch.load(\"./our_dos_classifier_reduced_inceptionresnet.pth\", weights_only=True))\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train(model, device, train_loader, optimizer, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2520/3001 (83.97%)\n",
      "Precision: 0.8397, Recall: 0.8397, F1-score: 0.8397\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model, device, test_loader, criterion)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./our_dos_classifier_reduced_inceptionresnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels_in_subset(dataset):\n",
    "    label_count = Counter()\n",
    "    for _, label in dataset:\n",
    "        label_count[label] += 1  # Directly count the label since it's an int\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution: Counter({0: 1123, 1: 1107})\n",
      "Testing set label distribution: Counter({0: 304, 1: 254})\n"
     ]
    }
   ],
   "source": [
    "train_label_count = count_labels_in_subset(train_dataset)\n",
    "test_label_count = count_labels_in_subset(test_dataset)\n",
    "\n",
    "# Print the label distribution\n",
    "print(f\"Training set label distribution: {train_label_count}\")\n",
    "print(f\"Testing set label distribution: {test_label_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 286498\n",
      "Trainable Parameters: 286498\n",
      "Frozen Parameters (Feature Extractor of Reduced Inception Resnet): 0\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    untrainable_params = total_params - trainable_params\n",
    "\n",
    "    return total_params, trainable_params, untrainable_params\n",
    "\n",
    "total_params, trainable_params, untrainable_params = count_parameters(model)\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "print(f\"Frozen Parameters (Feature Extractor of Reduced Inception Resnet): {untrainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
